\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage[linesnumbered, ruled, vlined, ngerman]{algorithm2e}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{array}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{listings}
\usepackage[justification=centering]{caption}
\usetikzlibrary{arrows, automata, graphs, shapes, petri, decorations.pathmorphing}

% define environments
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}[definition]{Beispiel}

\theoremstyle{plain}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{lemma}[definition]{Lemma}

\renewcommand{\labelenumi}{(\roman{enumi})}

\author{Niklas Rieken}
\title{First-Longest-Match Analyse}


\begin{document}
\maketitle

Wir schauen uns hier einmal eine praktische Anwendung von regulären Ausdrücken und endlichen Automaten an. Bisher haben wir stets das \textit{einfache Matching-Problem} für reguläre Ausdrücke betrachtet. Dabei ging es darum zu prüfen, ob ein gegebenes Wort \( w \in \Sigma^\ast \) zur Sprache eines regulären Ausdrucks \( r \in \mathsf{RE}_\Sigma \) gehört. Dies ließ sich mit Hilfe der Thompson-Konstruktion einfach als das Wortproblem eines \(\varepsilon\)-NFA betrachten. In der Praxis ist das einfach Matching-Problem aber zu primitiv um echte Probleme lösen zu können. Vorallem im Compilerbau benötigen wir etwas mehr, wenn wir Programmcode in seine Bestandteile zerlegen wollen um später Syntax-Checks darauf durchführen zu können und schließlich eine Semantik für das Programm festzulegen. In der Fachsprache nennt man diesen Teil eines Compilers auch \textit{Scanner} oder \textit{Lexer} (siehe auch \texttt{lex}, \texttt{flex}).


\subsection*{Problemstellung: Extended Matching Problem}
Das \textit{erweiterte (extended) Matching Problem} kommt direkt aus der Anwendung des Compilerbaus. Gegeben ist ein Wort \( w \in \Sigma^\ast \) und eine Reihe von regulären Ausdrücken \( r_1, \ldots, r_n \in \mathsf{RE}_\Sigma \). (\textit{Bemerkung:} In der Praxis ist die Annahme \( \varepsilon \notin L(r_i) \neq \emptyset \) für alle \( i \) sinnvoll). Gesucht ist nun eine Zerlegung von des Wortes \( w = u_1 \ldots u_k \), wobei für jedes \( u_j \) ein \( r_{i_j} \) existieren muss, sodass \( u_j \in L(r_{i_j}) \). Man nennt die Zerlegung in \( (u_1, \ldots, u_k) \) auch \textit{Dekomposition} und die zugehörigen Indizes der regulären Ausdrücke \( (i_1, \ldots, i_k) \) \textit{Analyse} von \( w \) bezüglich \( r_1, \ldots, r_n \).

Wir sehen schnell, dass weder Dekomposition, noch Analyse eindeutig sein müssen (insbesondere dann, wenn wir \( \varepsilon \in L(r_i) \) zulassen).
\begin{example}
	\begin{enumerate}
		\item \( r_1 = a^+, w = aa \). Ergibt Dekompositionen \( (aa) \) und \( (a, a) \) mit zugehöriger (eindeutiger) Analyse \( (1) \) bzw. \( (1, 1) \).
		\item \( r_1 = a+b, r_2 = a+c, w = a \). Ergibt eindeutige Dekomposition \( (a) \) mit zwei verschiedenen Analysen \( (1) \) und \( (2) \).	
	\end{enumerate}
	Im zweiten Fall stellen wir uns vor, dass \( r_1 \) mögliche Schlüsselwörter einer Programmiersprache (\texttt{while}, \texttt{true}, \texttt{if}) beschreibt und \( r_2 \) mögliche Variablennanem (Identifier), dann sieht man warum eine eindeutige Analyse wichtig ist. In diesem Anwendungsfall ist es natürlich zu sagen, dass der Ausdruck \( r_1 \) ''wichtiger`` ist als \( r_2 \) (deshalb verbieten die mesiten Programmiersprachen auch Schlüsselwörter als Identifier). Ähnliche Beispiele lassen sich auch für die Dekomposition finden.
\end{example}

Wir wollen nun sowohl, die Dekomposition, als auch die Analyse eindeutig machen. Ein erster Ansatz wäre zunächst das leere Wort zu verbieten und sicherzustellen, dass \( L(r_i) \cap L(r_j) = \emptyset \) für alle \( i \neq j \), indem wir den gemeinsamen Schnitt von zwei Ausdrücken aus dem ''unwichtigeren`` Ausdruck entfernen. Dadurch würde zumindest die Analyse eindeutig werden. Diese Idee ist jedoch nicht sinnvoll, u.a. deshalb, da das Entfernen des Schnittes -- also das Erkennen von \( L(r_j^\prime) \coloneqq L(r_j) \setminus L(r_i) \) -- eine Produktkonstruktion erfordert und somit tendenziell teuer ist.


\subsection*{Eindeutigkeit durch First-Longest-Match}
Der am meisten verbreitete Weg ist es folgende zwei Prinzipien zu implementieren:
\begin{description}
	\item[Longest Match] Mache jedes \( u_i \) der Zerlegung so lang wie möglich.
	\item[First Match] Wähle aus den matchenden regulären Ausdrücken den mit dem kleinesten Index.
\end{description}

\begin{definition}
	Eine Dekomposition \( (u_1, \ldots, u_k) \) von \( w \in \Sigma^\ast \) bezüglich \( r_1, \ldots, r_n \in \mathsf{RE}_\Sigma \) heißt \textit{Longest-Match-Dekomposition} (LMD), wenn für jedes \( i \in \{1, \ldots, k\} \), \( x \in \Sigma^+ \), \( y \in \Sigma^\ast \) mit \( w = u_1 \ldots u_i x y \) gilt, dass kein \( j \in \{1, \ldots, n\} \) existiert, sodass \( u_i x \in L(r_j) \). 
\end{definition}
Umgangssprachlich bedeutet das, dass wir an einen Teil der Komposition \( u_i \) kein nicht-leeres Wort mehr anhängen können, was noch nicht verarbeitet wurde.
Es ist klar, dass eine LMD eindeutig ist, falls sie existiert. Sie muss jedoch nicht immer existieren:

\begin{example}
	\( r_1 = a^+, r_2 = ab, w = aab \) hat Dekomposition \( (a, ab) \) aber keine LMD.
\end{example}

\begin{definition}
	Sei \( u_1, \ldots, u_k) \) eine LMD von \( w \in \Sigma^\ast \) bezüglich \( r_1, \ldots, r_n \in \mathsf{RE}_\Sigma \). Die zugehörige \textit{First-Longest-Match-Analyse} (FLM-Analyse) \( (i_1, \ldots, i_k) \) is gegeben durch
	\[
		i_j \coloneqq \min \{ \ell \mid u_j \in L(r_\ell) \}
	\]
	für jedes \( j \in \{1, \ldots, k\} \).
\end{definition}
Auch hier ist klar, dass es höchstens eine FLM-Analyse gibt und sie existiert, wenn die LMD existiert.


\subsection*{Eine mögliche Implementierung}
Es gibt viele Möglichkeiten eine FLM-Analyse durchzuführen. Die von mir hier vorgestellte Art ist nicht die von mir favorisierte, aber sie ist insofern intuitiv, als dass sie nur Konzepte aus der FoSAP-Vorlesung verwendet und ein wenig über Arrays.

Als Eingabe erhalten wir also \( w \in \Sigma^\ast \) und die regulären Ausdrücke \( r_1, \ldots, r_n \in \mathsf{RE}_\Sigma \). Gesucht ist eine FLM-Analyse inklusive zugehöriger LMD oder ein Error, falls diese nicht existieren.

\begin{algorithm}
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\SetKwComment{Comment}{\texttt{// }}{}
	\underline{FLM}{($w, (r_i)_{i=1}^n$)}\\
	\Output{FLM-Analyse $(i_j)_{j=1}^k$ und LMD $(u_j)_{j=1}^k$}	
	\Comment{Vorbereitung}
	Wandle alle \( r_i \) mit Thompson-Konstruktion in \(\varepsilon\)-NFAs \( \mathcal{A}_i = (Q_i, \Sigma, \delta_i, q_0^i, F_i) \) um.\\
	Baue neuen $\varepsilon$-NFA $\mathcal{A} = (\bigcup_i Q_i \cup \{q_0, q_f\}, \Sigma \uplus \{1, \ldots, n\}, \delta, q_0, \{q_f\})$ mit $\delta(p, a) = \delta_i(p, a)$ falls $p \in Q_i$ und $\delta(q_0, \varepsilon) = \{q_0^i \mid i = 1, \ldots, n\}$ und $\delta(q, i) = \{q_f\}$, falls $q \in F_i$.\\
	Eliminiere $\varepsilon$-Transitionen.\\
	Determinisiere mit Potenzmengenkonstruktion.\\
	Minimiere mit Markierungsalgorithmus.\\
	\tcc{Wir haben nun einen Automaten mit folgender Eigenschaft: Vom Zustand $\hat{\delta}(q_0, u)$ ist genau dann eine Transition mit $i = 1, \ldots, n$ möglich, wenn $u \in L(r_i)$.}
	\Comment{Löse nun das erweiterte Matching-Problem}	
	$\ell = 1, w_\ell = w$\\
	\While{$w_\ell \neq \varepsilon$}{
		\texttt{A} = leeres Array der Länge $\left| w_\ell \right|$\\
		Simuliere $\mathcal{A}$ auf $w_\ell$, prüfe in jedem Schritt $j$, ob eine $i$-Transition in einen akzeptierenden Zustand möglich ist.
		Falls ja, setze \texttt{A[$j$]} auf das kleinste mögliche $i$.\\
		Nach der Simulation laufe \texttt{A} von hinten nach vorne durch bis wir den ersten nicht-leeren Eintrag an Stelle $h$ finden. Sollte es keinen geben gebe einen Error aus, ansonsten ist $u_\ell = w_{\ell_1} \ldots w_{\ell_h}$ und $i_\ell = \texttt{A[}h\texttt{]}$.\\
		Setze $w_{\ell+1} = w_{\ell_h} \ldots w_{\ell_{\left| w_\ell \right|}}, \ell = \ell+1$.
	}
	\Comment{Jetzt ist $w_\ell = \varepsilon$}
	Gebe $(u_1, \ldots, u_{\ell-1})$ und $(i_1, \ldots, i_{\ell-1})$ aus.
	\caption{Pseudocode}
	\label{alg:algorithm-label}
\end{algorithm}

\end{document}