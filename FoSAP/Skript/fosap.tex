\documentclass[11pt, a4paper]{article}

% packages
\usepackage{natbib}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{stmaryrd}
\usepackage{amsthm}
\usepackage{tikz}
\usepackage{mathrsfs}
\usepackage{mathdots}
\usepackage{mathtools}
\usepackage{listings}
\usepackage[linesnumbered, ruled, vlined, ngerman]{algorithm2e}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{float}
\usepackage[justification=centering]{caption}
\usepackage{subcaption}
\usetikzlibrary{arrows, automata, graphs, shapes, petri, decorations.pathmorphing}

% meta
\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000
\parindent = 0pt

% define environments
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}[definition]{Beispiel}
\newtheorem*{example*}{Beispiel}
\newtheorem*{remark*}{Bemerkung}

\theoremstyle{plain}
\newtheorem{theorem}[definition]{Satz}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{corollary}[definition]{Korollar}

\numberwithin{equation}{section}

\renewcommand{\labelenumi}{(\roman{enumi})}
\makeatletter
\newcommand*{\shifttext}[2]{
	\settowidth{\@tempdima}{#2}
	\makebox[\@tempdima]{\hspace*{#1}#2}
}
\makeatother
\def\Rho{\mathrm{P}}

\newenvironment{problem}[1]{\begin{tabular}{|p{.96\textwidth}|} \hline \textsc{#1}\\}{\\ \hline \end{tabular}}
\newcommand{\comp}[1]{\overline{#1}}
\newcommand{\qedw}{\hfill\(\square\)}
\newcommand{\qedb}{\hfill\(\blacksquare\)}
\newcommand{\shuffle}{\mathrel{\shifttext{5pt}{$\equiv$}\shifttext{-5pt}{$=$}}}
\newcommand{\reaches}[1]{\overset{#1}{\rightarrow}}

\lstset{numbers=left, xleftmargin=.2\textwidth, xrightmargin=.2\textwidth, basicstyle=\ttfamily\bfseries}

% Here we go...
\begin{document}

% title page
\pagestyle{empty}
\begin{center}
    Rheinisch-Westf\"alische Technische Hochschule Aachen\\[10em]

    \begin{LARGE}
    		Skript zur Vorlesung\\[1.5em]
		\textbf{Formale Systeme, Automaten, Prozesse}
    \end{LARGE}
	\vfill
    \begin{Large}
    		Letzte Änderung:\\
    		\today\\[2em]
		Autor:\\
		Niklas Rieken\\
	\end{Large}
	\vfill
	\includegraphics[scale=.4]{icons/cc.png}
	\includegraphics[scale=.4]{icons/by.png}
	\includegraphics[scale=.4]{icons/sa.png}\\
	Dieses Werk ist lizenziert unter einer Creative Commons Namensnennung -- Weitergabe unter gleichen Bedingungen 4.0 International Lizenz.
\end{center}


\newpage
% acknowledgements
\vspace*{\fill}
\section*{Hinweise}
Dieses Skript entstand aus der Vorlesung Formale Systeme, Automaten, Prozesse an der RWTH Aachen von Prof. Dr. Wolfgang Thomas und Prof. Dr. Martin Grohe vom Lehrstuhl Informatik~7 in den Sommersemestern 2015 und 2016. Ein paar Notationen und Definitionen sind außerdem adaptiert aus dem Skript zu den Diskreten Strukturen und Lineare Algebra I für Informatiker von Dr. Timo Hanke und Prof. Dr. Gerhard Hiß vom Lehrstuhl~D für Mathematik.
\vspace*{\fill}


\newpage
% table of contents
\tableofcontents


\newpage
\pagestyle{headings}
\section{Mathematisches Vorwissen}\label{sec:pre}
In diesem ersten Kapitel fixieren wir einige mathematischen Notationen und geben elementare Sätze aus der diskreten Mathematik, die im weiteren verlauf der Vorlesung benötigt werden. In der Regel sollten sämtliche Begriffe und Notationen aus dem ersten Semester bereits bekannt sein. Deshalb ist dieses Kapitel eher nur für Sommersemesteranfänger bestimmt.


\subsection{Mengen}\label{sec:pre_sets}
Der Begriff Menge geht auf Georg Cantor aus dem 19. Jahrhundert zurück und wurde (verglichen mit späteren Definitionen in diesem Skript) informell beschrieben.
\begin{quote}
	Unter einer ``Menge`` verstehen wir jede Zusammenfassung \( M \) von bestimmten wohlunterschiedenen Objekten \( m \) unserer Anschauung oder unseres Denkens (welche die ``Elemente`` von \( M \) genannt werden) zu einem Ganzen.
\end{quote}

Wir definieren eine Menge wie folgt
\begin{definition}
	Eine \textit{Menge} \( M \) ist etwas, zu dem jedes beliebige Objekt \( x \) entweder \textit{Element} der Menge ist (\( x \in M \)), oder nicht (\( x \notin M \)).
\end{definition}
Mengen selbst können auch wieder als Objekte aufgefasst werden, also Elemente anderer Mengen sein. Wir vermeiden jedoch Aussagen über ``Mengen, die sich selbst enthalten``, da so schnell Widersprüche entstehen können (vgl. Russel'sche Antinomie). Wir schließen uns der weit verbreiteten \textit{Zermelo-Fraenkel-Mengenlehre} an, dazu geben wir jedoch keine Details (diese findet man zum Beispiel in der Logik 2-Vorlesung im Wahlpflichtbereich). Wir schauen uns nur an, wie wir Mengen im allgemeinen betrachten können. Folgende Definition sind dabei elementar.
\begin{definition}\label{def:subsets}
	Seien \( M, N \) zwei Mengen. \( N \) ist eine \textit{Teilmenge} von \( M \) (\( N \subseteq M \)) bzw. \( M \) eine \textit{Obermenge} von \( N \) (\( M \supseteq N \)), wenn für alle \( x \in N \) gilt, dass auch \( x \in M \).\\
	Wir sagen \( N \) ist eine \textit{echte Teilmenge} von \( M \) (\( N \subset M \)) bzw. \( M \) eine \textit{echte Obermenge} von \( N \) (\( M \supset N \)), wenn es zusätzlich ein \( y \in M \) gibt mit \( y \notin N \).\\
	\( M \) und \( N \) sind \textit{gleich} (\( M = N \)), wenn sowohl \( M \subseteq N \) als auch \( N \subseteq M \) gilt.
\end{definition}
Wir kommen nun zum Mächtigkeitsbegriff der Mengenlehre, der für die Anzahl der Elemente einer Menge beschreibt.
\begin{definition}
	Sei \( M \) eine Menge. \( M \) heißt \textit{endlich}, wenn \( M \) nur endlich viele Elemente besitzt, dann beschreibt \( \left| M \right| \) die Anzahl der Elemente von \( M \). Andernfalls heißt \( M \) \textit{unendlich} und wir schreiben \( \left| M \right| = \infty \). Man nennt \( \left| M \right| \) die \textit{Mächtigkeit} von \( M \).
\end{definition}
Um eine konkrete Menge zu zu benennen gibt es im Wesentlichen vier verschiedene Möglichkeiten:
\begin{enumerate}
	\item \textit{Aufzählen.} Die Elemente der Menge werden aufgelistet und in Mengenklammern (\( \{, \} \)) eingeschlossen. Reihenfolge und Wiederholungen spielen keine Rolle.
		\[
			\{ 3, 4.5, \pi, \diamondsuit \} = \{ \pi, 4.5, \diamondsuit, \diamondsuit, 3 \} \subseteq \{ \diamondsuit, \pi, 4.5, 3, \clubsuit \}. 
		\]
	\item \textit{Beschreiben.} Mengen können durch Worte beschrieben werden.
		\[
			\text{Menge der natürlichen Zahlen} = \{ 0, 1, 2, 3, \ldots \} \eqqcolon \mathbb{N}.
		\]
		Aber Achtung: Natürliche Sprache neigt zu Uneindeutigkeit!
	\item \textit{Aussondern.} Sei \( M \) eine Menge, dann ist
		\[
			\{ x \in M \mid A(x) \}
		\]
		die Menge aller Elemente aus \( M \), die die Aussage \( A \) erfüllen. Zum Beispiel:
		\[
			\mathbb{P} \coloneqq \{ n \in \mathbb{N} \mid n \text{ hat genau zwei Teiler} \}
		\]
		als Menge aller Primzahlen.
	\item \textit{Abbilden.} Sei \( M \) eine Menge und \( f \) ein Ausdruck, der für jedes \( x \in M \) definiert ist. Dann ist
		\[
			\{ f(x) : x \in M \}
		\]
		die Menge aller Ausdrücke \( f(x) \), wobei jedes \( x \in M \) in \( f \) eingesetzt wird. Zum Beispiel:
		\[
			\{ n^2 : n \in \mathbb{N} \}
		\]
		als Menge aller Quadtratzahlen.
\end{enumerate}
Wir können Abbilden und Aussondern auch kombinieren, zum Beispiel mit:
\[
	\{ n^2 : n \in \mathbb{N} \mid n \text{ ungerade} \}
\]
als Menge aller Quadratzahlen von ungeraden natürlichen Zahlen. Man würde hier jedoch abkürzend schreiben:
\[
	\{ n^2 : n \in \mathbb{N} \text{ ungerade} \}
\]
oder auch
\[
	\{ n^2 : n \in 2\mathbb{N}+1 \}.
\]

Eine wichtige Menge haben wir bisher außen vor gelassen: die \textit{leere Menge}. Wir schreiben \( \emptyset \coloneqq \{ \} \). Gelegentlich verwenden wir außerdem folgende Notation, wenn wir nur eine endliche geordnete Menge benötigen: \( [\ell] \coloneqq \{ 0, 1, \ldots, \ell-1 \} \). Ein-elementige Mengen (z.B. \( [1] = \{ 0 \} \)) nennt man auch \textit{Singleton}.


\subsection{Operationen auf Mengen}\label{sec:pre_setops}
Im folgendem betrachten wir Mengen immer als Teilmenge eines \textit{Universums} (oder auch Grundemenge) \( \mathcal{U} \). In der Analysis ist das typischerweise die Menge der reellen Zahlen \( \mathbb{R} \) (solange man die komplexen Zahlen eben weglässt), die betrachteten Teilmengen sind oftmals Intervalle in denen zum Beispiel Funktionen auf Stetigkeit hin untersucht werden. Vorweg: Wir betrachten später im Allgemeinen das Universum \( \Sigma^\ast \) und Sprachen als Teilmenge von eben diesem. Genaueres folgt im nächsten Kapitel.\\
Um die Operatoren auf den Mengen zu veranschaulichen gibt es die sogenannten \textit{Venn-Diagramme}, bei denen Kreise oder Ellipsen die Mengen visualisieren. In Abbildung~\ref{fig:venn_subset} finden wir zum Beispiel für die Inklusion (\( \subseteq \)) ein entsprechendes Diagramm.
\begin{figure}
	\centering
	\input{figs/venn_subset}
	\caption{Venn-Diagramm für \( A \subseteq B \).}
	\label{fig:venn_subset}
\end{figure}
Wir definieren nun einige Operationen auf Mengen ähnlich wie Addition und Multiplikation usw. auf Zahlen. Zusätzlich zur formalen Definition befindet sich in Abbildung~\ref{fig:venn} auch ein passendes Venn-Diagramm. Die jeweils eingefärbte Fläche kennzeichnet die resultierende Menge. \( \mathcal{U} \) sei ein beliebiges aber festes Universum.
\begin{definition}\label{def:setops}
	Seien \( A, B \) Mengen. 
	\begin{enumerate}[label=(\alph*)]
		\item Die \textit{Vereinigung} von \( A \) und \( B \) ist definiert als 
			\[ 
				A \cup B \coloneqq \{ a \in \mathcal{U} \mid a \in A \text{ oder } a \in B \}.
			\]
			Für endliche und unendliche Vereinigungen (z.B. gegeben durch eine Indexmenge \( I = \{ 0, 1, \ldots \} \)) schreiben wir abkürzend
			\[
				\bigcup_{i \in I} A_i = A_0 \cup A_1 \cup \ldots
			\]
		\item Der \textit{Schnitt} von \( A \) und \( B \) ist definiert als
			\[
				A \cap B \coloneqq \{ a \in A \mid a \in B \}.
			\]
			Für endlichen und unendlichen Schnitt (z.B. gegeben durch eine Indexmenge \( I = \{ 0, 1, \ldots \} \)) schreiben wir abkürzend
			\[
				\bigcap_{i \in I} A_i = A_0 \cap A_1 \cap \ldots
			\]
		\item Das \textit{Komplement} von \( A \) is definiert als
			\[
				\comp{A} \coloneqq \{ a \in \mathcal{U} \mid a \notin A \}.
			\]
		\item Die \textit{Differenz} (auch: relatives Komplement) von \( A \) und \( B \) ist definiert als
			\[
				A \setminus B \coloneqq A \cap \comp{B}.
			\]
		\item Das \textit{kartesische Produkt} zwischen \( A \) und \( B \) ist definiert als
			\[
				A \times B \coloneqq \{(a, b) : a \in A, b \in B \}.
			\]
			Für ein endliches Produkt einer Menge \( A \) auf sich selbst schreiben wir abkürzend
			\[
				A^k \coloneqq A \times A^{k-1}, \quad\quad A^1 \coloneqq A, \quad\quad A^0 \coloneqq \{ \bullet \},
			\]
			wobei \( \bullet \) ein beliebiges Platzhaltersymbol ist, d.h. \( A^0 \) ist für jedes \( A \) ein Singleton.\\
			Die Elemente eines kartesischen Produkts \( (x_1, \ldots, x_k) \) heißen \( k\)-\textit{Tupel}. Für \( k = 2, 3, 4, \ldots \) kann man auch \textit{Paar, Tripel, Quadrupel, \ldots} sagen.
		\item Die \textit{Potenzmenge} von \( A \) ist definiert als
			\[
				2^A \coloneqq \{ M \subseteq \mathcal{U} \mid M \subseteq A \}.
			\]
	\end{enumerate}
\end{definition}
\begin{figure}
	\centering
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/venn_union}
		\caption{\( A \cup B \)}
		\label{fig:venn_union}
	\end{subfigure}
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/venn_intersection}
		\caption{\( A \cap B \)}
		\label{fig:venn_intersection}
	\end{subfigure}\\
	\ \\
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/venn_complement}
		\caption{\( \comp{A} \)}
		\label{fig:venn_complement}
	\end{subfigure}
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/venn_setminus}
		\caption{\( A \setminus B \)}
		\label{fig:venn_setminus}
	\end{subfigure}
	\caption{Venn-Diagramme für Mengen-Operationen.}
	\label{fig:venn}
\end{figure}


\subsection{Relationen}\label{sec:pre_relations}
Relationen drücken Beziehungen oder Zusammenhänge zwischen Elementen aus. Im Allgemeinen können dies Beziehungen zwischen beliebig vielen Elementen sein und wir werden verschieden stellige Relationen auch im Laufe der Vorlesung benutzen. In diesem Abschnitt legen wir aber ein besonderes Augenmerk auf 2-stellige Relationen.
\begin{definition}
	Es seien \( M_1, \ldots, M_k \) nicht-leere Mengen. Eine Teilmenge \( R \subseteq M_1 \times \ldots \times M_k \) heißt \textit{Relation} zwischen \( M_1, \ldots, M_k \) (oder auf \( M \), falls \( M = M_1 = \ldots = M_k \)).
\end{definition}
Für 2-stellige Relationen verwenden wir oft Symbole wie \( \sim, \prec \) und schreiben dann statt \( (a, b) \in\, \sim \) intuitiver \( a \sim b \).
\begin{definition}
	Sei \( \sim \,\subseteq M \times M \) eine 2-stellige Relation. \( \sim \) heißt
	\begin{itemize}
		\item \textit{reflexiv}, falls \( x \sim x \) für alle \( x \in M \),
		\item \textit{symmetrisch}, falls für alle \( x, y \in M \) mit \( x \sim y \) auch \( y \sim x \) gilt,
		\item \textit{antisymmetrisch}, falls für alle \( x, y \in M \) mit \( x \sim y \) und \( y \sim x \) gilt, dass \( x = y \),
		\item \textit{transitiv}, falls für alle \( x, y, z \in M \) mit \( x \sim y \) und \( y \sim z \) gilt, dass \( x \sim z \).
	\end{itemize}
\end{definition}
Wir klassifizieren außerdem 2-stellige Relationen, falls sie bestimmte Eigenschaften haben.
\begin{definition}
	Sei \( \sim \,\subseteq M \times M \) eine 2-stellige Relation. \( \sim \) heißt
	\begin{itemize}
		\item \textit{Äquivalenzrelation}, falls sie reflexiv, symmetrisch und transitiv ist,
		\item \textit{(partielle) Ordnung}, falls sie reflexiv, antisymmetrisch und transitiv ist,
		\item \textit{Totalordnung}, falls sie partielle Ordnung ist und für alle \( x, y \in M \) entweder \( x \sim y \) oder \( y \sim x \) gilt. 
	\end{itemize}	 
\end{definition}
\begin{example*}
	\
	\begin{enumerate}
		\item Die Relation \( \leq \) ist auf \( \mathbb{N} \) eine Totalordnung.
		\item Die Relation \( \{(a, b) \subseteq \mathbb{R}^2 \mid a^2 = b^2 \} \) ist eine Äquivalenzrelation auf \( \mathbb{R} \).
	\end{enumerate}
\end{example*}

\begin{definition}
	Sei \( \sim \) eine Äquivalenzrelation auf einer Menge \( M \). Für \( x \in M \) heißt
	\[
		[x] \coloneqq [x]_\sim \coloneqq \{ y \in M \mid x \sim y \}
	\]
	die \textit{Äquivalenzklasse} von \( x \). Die Menge aller Äquivalenzklassen von \( \sim \) wird notiert mit \( M /_\sim \coloneqq \{ [x]_\sim : x \in M \} \).
\end{definition}



\subsection{Gesetze für Mengen}\label{sec:pre_setlaws}
In diesem Abschnitt sammeln wir ein paar Gesetzmäßigkeiten, die für Mengen gelten. Manche davon sind offensichtlich, wir werden aber auch zu ein paar Aussagen die Beweise geben, manche bleiben als Übung.
\begin{remark*}
	Für die Inklusion gilt offensichtlich für jede Menge \( M \)
	\[
		\emptyset \subseteq M \subseteq M \subseteq \mathcal{U}.
	\]
	Insbesondere ist die Relation \( \subseteq \) reflexiv. Sie ist außerdem transitiv und per Definition der Gleichheit von Mengen antisymmetrisch, also eine partielle Ordnung.\par
	Schnitt und Vereinigung sind per Definition offenbar \textit{assoziativ} (d.h. \( A \cup (B \cup C) = (A \cup B) \cup C \) und \( A \cap (B \cap C) = (A \cap B) \cap C \)) und \textit{kommutativ} (d.h. \( A \cup B = B \cup A \) und \( A \cap B = B \cap A \)). Außerdem sind diese beiden Operationen zueinander \textit{distributiv}, was wir im folgenden einmal zeigen wollen. 
\end{remark*}
Das Beweisschema für solche Aufgaben ist stets das selbe und sollte deshalb auch ruhig übernommen werden für Übungsaufgaben. Tricks sind selten notwendig, es ist meist
\begin{center}
	\textit{Definition anwenden -- triviale Umformung -- Definition anwenden -- Profit}.
\end{center}
\begin{remark*}
	Für Mengen \( A, B, C \) gilt:
	\begin{enumerate}
		\item \( A \cup (B \cap C) = (A \cup B) \cap (A \cup C) \),
		\item \( A \cap (B \cup C) = (A \cap B) \cup (A \cap C) \).
	\end{enumerate}
	\begin{proof}
		Wir zeigen nur Aussage (i), die zweite Hälfte geht analog. Wir müssen zwei Richtungen beweisen.\\
		``\( \subseteq \)``: Sei \( a \in A \cup (B \cap C) \). D.h. \( a \in A \) oder \( a \in B \cap C \).
		\begin{itemize}
			\item \( a \in A \). Dann ist \( a \) auch in \( A \cup B \) und \( A \cup C \) (da \( \cup \) die Mengen nicht verkleinert). Also ist \( a \) auch im Schnitt dieser beiden Mengen.
			\item \( a \in B \cap C \). Dann ist \( a \in B \) und \( a \in C \). Also (da wie oben \( \cup \) die Menge nicht verkleinert) ist \( a \in A \cup B \) und \( a \in A \cup C \). Somit ist \( a \) auch wieder im Schnitt beider Mengen.
		\end{itemize}
		``\( \supseteq \)``: Sei \( a \in (A \cup B) \cap (A \cup C) \). Dann ist \( a \in A \cup B \) und \( a \in A \cup C \) (\( \ast \)). Wir unterscheiden zwei Fälle:
		\begin{itemize}
			\item \( a \in A \). Unabhängig von \( B, C \) ist dann \( a \in A \cup (B \cap C) \).
			\item \( a \notin A \). Dann muss \( a \in B \) und \( a \in C \) gelten, sonst würde (\( \ast \)) nicht gelten. Somit ist \( a \in B \cap C \) und damit auch wieder \( a \in A \cup (B \cap C) \). 
		\end{itemize}
		Wir haben also \( A \cup (B \cap C) \subseteq (A \cup B) \cap (A \cup C) \) und \( A \cup (B \cap C) \supseteq (A \cup B) \cap (A \cup C) \) gezeigt. Somit muss Gleichheit zwischen diesen beiden Mengen vorliegen.
	\end{proof}
\end{remark*}
Weiterhin nützlich sind noch folgende Bemerkungen.
\begin{remark*}[DeMorgan'sche Gesetze]
	Für Mengen \( A, B \) gilt:
	\begin{itemize}
		\item \( \comp{(A \cup B)} = \comp{A} \cap \comp{B} \),
		\item \( \comp{(A \cap B)} = \comp{A} \cup \comp{B} \).
	\end{itemize}
\end{remark*}
\begin{remark*}[Absorptionsgesetz]
	Für Mengen \( A, B \) gilt:
	\begin{itemize}
		\item \( A \cup (A \cap B) = A \),
		\item \( A \cap (A \cup B) = A \).
	\end{itemize}
\end{remark*}
Die Beweise hierfür bleiben als Übung.


\subsection{Abbildungen}\label{sec:pre_mappings}
\begin{definition}
	Seien \( M, N \) Mengen. Eine \textit{Abbildung} \( f \) von \( M \) nach \( N \) ist eine Vorschrift (z.B. eine Formel), die jedem \( x \in M \) genau ein \( f(x) \in N \) zuordnet. Wir schreiben dazu
	\[
		f\colon M \to N, \quad x \mapsto f(x).
	\]
	\( M \) heißt der \textit{Definitionsbereich} (auch Domäne) von \( f \), \( N \) heißt der \textit{Wertebereich} von \( f \). \( f(x) \) ist das \textit{Bild} von \( x \) unter \( f \) und \( x \) ist ein \textit{Urbild} von \( f(x) \) unter \( f \). Die Menge aller Abbildungen von \( M \) nach \( N \) wird mit \( N^M \) bezeichnet. 
\end{definition}

\begin{definition}
	Eine Abbildung \( f\colon M \to N \) heißt
	\begin{itemize}
		\item \textit{surjektiv}, falls für alle \( y \in N \) ein \( x \in M \) mit \( f(x) = y \) existiert,
		\item \textit{injektiv}, falls für alle \( x, x^\prime \in M \) mit \( x \neq x^\prime \) gilt, dass \( f(x) \neq f(x^\prime) \),
		\item \textit{bijektiv}, falls \( f \) surjektiv und injektiv ist.
	\end{itemize}
\end{definition}
\begin{example*}
	Die Addition zweier natürlicher Zahlen kann als Abbildung aufgefasst werden:
	\[
		+\colon \mathbb{N}^2 \to \mathbb{N}, \quad (m, n) \mapsto m+n.
	\]
	\( + \) ist surjektiv (jedes \( y \in \mathbb{N} \) wird z.B. durch \( (y, 0) \in \mathbb{N}^2 \) getroffen), aber nicht injektiv (\( 1 \in \mathbb{N} \) wird sowohl von \( (1, 0) \) als auch \( (0, 1) \) getroffen).
\end{example*}
Für Abbildungen \( f\colon [k] \to M \) für beliebige \( k \in \mathbb{N} \) in beliebige \( M \) können wir auch abkürzend die Tupelschreibweise \( (y_0, \ldots, y_{k-1}) \) verwenden. Dann ist \( y_i = f(i) \) für alle \( i \in [k] \).


\subsection{Strukturen}\label{sec:pre_structures}

\subsection{Graphen}\label{sec:pre_graphs}

\subsection{Beweismethoden}\label{sec:pre_proofs}



\newpage
\section{Alphabete, Wörter, Sprachen}\label{sec:awl}
Das erste Kapitel hat uns mit den nötigen mathematischen Grundlagen versorgt, die wir als Modellierungswerkzeuge in der theoretischen Informatik verwenden wollen. Wir definieren dazu später abstrakte Rechenmodelle, sogenannte Automaten, um das Verhalten von konkreten Rechenmodellen (z.B. Computern) formal zu erfassen. Zunächst sehen wir uns an, wie wir ganz allgemein diese konkreten Rechenmodelle funktionieren und wie sich diese Funktionsweisen möglichst knapp und allgemein (d.h. abstrakt, ``vereinfacht auf das wesentliche``) darstellen lassen. Nach diesem Kapitel haben wir das Hauptthema der Vorlesung, die \textit{abstrakte Automatentheorie}, vorbereitet.

\subsection{Grundlegende Definitionen}\label{sec:awl_def}
Wir fassen Aktionen eines Computers (oder eines Getränkeautomaten, \ldots) in unserer Abstrakion als \textit{Symbole} (Buchstaben) auf, im Rahmen dieser Vorlesung sind das immer nur endlich viele, d.h. das \textit{Alphabet} ist endlich. Aktionsfolgen (z.B. vom Einwurf einer Münze bis zur Ausgabe des Getränkes) entsprechen somit einem \textit{Wort}. Die Menge aller gültigen Aktionsfolgen (solche, die für das betrachtete System ``sinnvoll`` sind) bezeichnen wir dann als \textit{Sprache des Automaten}.
\begin{definition}
	Ein \textit{Alphabet} ist eine nicht-leere endliche Menge, deren Elemente als \textit{Symbole} bezeichnet sind.
\end{definition}
Alphabete werden durch griechische Großbuchstaben \( \Sigma, \Gamma \) oder Variationen wie \( \Sigma_1, \Gamma^\prime \) bezeichnet. Symbole werden durch kleine lateinische Buchstaben \( a, b, c, \ldots \) oder arabische Ziffern bezeichnet.
\begin{example}
	\
	\begin{enumerate}
		\item Das \textit{Boole'sche Alphabet} \( \{ 0, 1 \} \).
		\item Das \textit{Morsealphabet} \( \{ \cdot, -, \,\,\, \} \).
		\item Das \textit{ASCII-Alphabet} für zum Beispiel Textdateien.
	\end{enumerate}
\end{example}

\begin{definition}
	Ein \textit{Wort} über einem Alphabet \( \Sigma \) ist eine Abbildung
	\[
		w\colon [n] \to \Sigma.
	\]
	Für \( n = 0 \) ist \( w\colon \emptyset \to \Sigma \) das \textit{leere Wort}, was wir als \( \varepsilon \) bezeichnen.\\
	Die \textit{Länge} des Wortes \( w \) ist bezeichnet mit \( \left| w \right| = n \).\\
	\( \left| w \right|_a \coloneqq \left| \{ i \in [n] \mid w(i) = a \} \right| \) ist die \textit{Häufigkeit des Symbols} \( a \) im Wort \( w \).
\end{definition}
Wie in Abschnitt~\ref{sec:pre_mappings} lässt sich \( w \) auch als Tupel \( (a_0, \ldots, a_{n-1}) \) schreiben. Wir gehen hier sogar noch einen Schritt weiter und benutzen \( a_0 a_1 \ldots a_{n-1} \) als Abkürzung für die langen Schreibweisen. Für Wörter verwenden wir in der Regel \( u, v, w \) und Varianten als Bezeichner. In der Literatur sind auch kleine griechische Buchstaben \( \alpha, \beta, \ldots \) gebräuchlich.
\begin{definition}
	Sei \( \Sigma \) ein Alphabet. Dann ist \( \Sigma^n \coloneqq \Sigma^{[n]} \) die \textit{Menge aller Wörter mit Länge} \( n \) über \( \Sigma \).
	Die \textit{Menge aller Wörter} ist definiert als
	\[
		\Sigma^\ast \coloneqq \bigcup_{n \in \mathbb{N}} \Sigma^n
	\]
	und \( \Sigma^+ \coloneqq \Sigma^\ast \setminus \{ \varepsilon \} \).
\end{definition}
Wie in Abschnitt~\ref{sec:pre_setops} angekündigt wird für ein fixiertes \( \Sigma \) die Menge \( \Sigma^\ast \) unser Universum sein.
\begin{definition}
	Eine \textit{(formale) Sprache} über einem Alphabet \( \Sigma \) ist eine Teilmenge von \( \Sigma^\ast \).
\end{definition}
Sprachen bezeichnen wir in der Regel mit \( L, K, \ldots \) und Varianten.
\begin{example}
	\
	\begin{itemize}
		\item Die leere Sprache \( \emptyset \).
		\item Die Sprache, die nur das leere Wort enthält \( \{ \varepsilon \} \).
		\item Die Sprache aller Binärdarstellungen von Primzahlen \( \{ bin(n) : n \in \mathbb{P} \} \).
		\item Die Menge aller grammatikalisch korrekten deutschen Sätze.
	\end{itemize}
\end{example}


\subsection{Operationen und Relationen auf Wörtern und Sprachen}\label{sec:awl_wordops}
Durch diese vorgegangen Definitionen haben wir das Fundament für die theoretische Informatik bereits definiert. Da dies nur mithilfe von Funktionen und Mengen  passiert ist lassen sich Beweismethoden und Ergebnisse aus der Mathematik einfach übertragen. Wir definieren nun noch ein paar Operationen auf Wörtern und erweitern diese Definitionen auf Sprachen.
\begin{definition}
	Seien \( u, v \in \Sigma^\ast \) mit \( m = \left| u \right|, n = \left| v \right| \). Die \textit{Konkatenation} (Verkettung) ist definiert als
	\begin{align*}
		(u \cdot v)&\colon [m{+}n] \to \Sigma \text{ mit}\\
		(u \cdot v)(i) &= \left\lbrace \begin{array}{ll}u(i), & i < m\\ v(i-m), & i \geq m. \end{array} \right.
	\end{align*}
	Außerdem ist \( u^0 \coloneqq \varepsilon \) und \( u^n \coloneqq u \cdot u^{n-1} \).
\end{definition}
Aus Bequemlichkeitsgründen wird der Punkt auch weggelassen. Für Sprachen erhalten wir noch die Definitionen.
\begin{definition}
	Seien \( L, K \subseteq \Sigma^\ast \) Sprachen.
	\begin{enumerate}
		\item \textit{Konkatenation.} \( L \cdot K \coloneqq \{ uv : u \in L, v \in K \} \) und \( L^0 \coloneqq \{ \varepsilon \}, L^n \coloneqq L \cdot L^{n-1} \).
		\item \textit{Inklusion.} Wie in Definition~\ref{def:subsets}.
		\item \textit{Vereinigung, Schnitt, Komplement, Differenz.} Wie in Definiton~\ref{def:setops}.
		\item \textit{Kleene'scher Abschluss.} (auch Iteration, Kleene-Stern)
			\[
				L^\ast \coloneqq \bigcup_{n \in \mathbb{N}} L^n.
			\]
	\end{enumerate}
\end{definition}
\begin{definition}
	Seien \( u, v \) Wörter. Dann ist \( u \)
	\begin{itemize}
		\item \textit{Präfix} von \( v \) (geschrieben: \( u \sqsubseteq v \)), falls es ein Wort \( w \) gibt mit \( v = uw \),
		\item \textit{Infix} von \( v \), falls es Wörter \( w, w^\prime \) gibt mit \( v = wuw^\prime \),
		\item \textit{Suffix} von \( v \), falls es ein Wort \( w \) gibt mit \( v = wu \).
	\end{itemize}
\end{definition}
\begin{example}
	Sei \( v = aaba \).
	\begin{itemize}
		\item Die Präfixe von \( v \) sind \( \varepsilon, a, aa, aab, aaba \).
		\item Die Suffixe von \( v \) sind \( \varepsilon, a, ba, aba, aaba \).
		\item Die Infixe von \( v \) sind alle Präfixe und Suffixe, sowie \( ab, b \).
	\end{itemize}
\end{example}


\subsection{Gesetze für Wörter und Sprachen}\label{sec:awl_wordlaws}
In diesem Abschnitt wollen wir einige Gesetzmäßigkeiten, die bei der Anwendung von Operationen auf Wörtern und Sprachen gelten, herausarbeiten. Einige Eigenschaften übertragen sich sofort aus denen für Mengen aus Abschnitt~\ref{sec:pre_setlaws}. Bei anderen ist etwas mehr zu zeigen und bei wieder anderen gibt es vielleicht auch zunächst unintuitive Unterschiede.
\begin{remark*}
	Für das leere Wort \( \varepsilon \) gilt:
	\begin{enumerate}
		\item Es ist für jedes Wort sowohl Präfix, Infix als auch Suffix.
		\item Es ist das \textit{neutrale Element} der Konkatenation, d.h. für alle \( w \in \Sigma^\ast \) gilt \( \varepsilon w = w = w \varepsilon \).
		\item Daran anknüpfend gilt für jede Sprache \( L \), dass \(  \{ \varepsilon \} L = L = L  \{ \varepsilon \} \).
		\item Für jede Menge \( A \) (inklusive dem Fall \( A = \emptyset \)) ist \( A^0 = \{ \varepsilon \} \).
		\item \( \varepsilon \) ist eindeutig, d.h. es gibt kein zweites Wort mit diesen Eigenschaften.
		\item Weil es häufig durcheinander gebracht wird: \( \{ \varepsilon \} \neq \emptyset \).
	\end{enumerate}
\end{remark*}

\begin{remark*}
	Für Vereinigung, Schnitt, Differenz, \ldots von Sprachen gelten die selben Regeln (Assoziativ-, Kommutativ-, Distributivgesetze, deMorgan, Absorption, \ldots) wie für Mengen.
\end{remark*}

\begin{remark*}
	Für jede Sprache \( L \) gilt, dass \( \emptyset L = L \emptyset = \emptyset \).
	\begin{proof}
		Wir zeigen, dass \( L \emptyset \) leer ist. Der andere Fall geht analog. Angenommen es existiert ein \( w \in L \emptyset \). Dann lässt sich \( w \) zerlegen in \( w = uv \) mit \( u \in L, v \in \emptyset \). Da ein solches \( v \) nicht existieren kann (leere Menge), kann auch die gesamte Zerlegung und somit auch \( w \) nicht existieren. Also ist \( L \emptyset \) leer.
	\end{proof}
\end{remark*}



\newpage
\section{Endliche Automaten und Reguläre Sprachen}\label{sec:regular}
Wir haben formale Sprachen eingeführt als Modellierung für Prozessabläufe auf z.B. Computern. Diese Ansicht werden wir zunächst aber beiseite legen und erst in Kapitel~\ref{sec:process} wieder aufgreifen. In der Zwischenzeit untersuchen wir Sprachen auf verschiedene Eigenschaften und klassifizieren unter anderem nach der sogenannten \textit{Chomsky-Hierarchie}. Wir prüfen, wie sich Sprachen von formalen Systemen (Automaten, abstrakte Rechenmodelle) erkennen lassen. Diese Systeme wirken manchmal etwas künstlich, sind aber sehr sinnvoll, da sie sich mit den uns zu Verfügungen Werkzeugen aus der Mathematik gut handhaben lassen. Die daraus entstehenden Resultate haben außerdem auch einen nicht zu vernachlässigenden ästhetischen Wert für die theoretische Informatik. Zugegeben, der Praxisbezug offenbart sich bei einigen Sätzen nicht sofort und ist vielleicht auch gar nicht überalll vorhanden. Dennoch sollte der Wert dieser Ergebnisse auch nicht unterschätzt werden, denn wir liefern hier auch die Grundlagen zur Untersuchung, was sich prinzipiell mit Computern überhaupt berechnen lässt und die Erkenntnis, dass es Probleme in der Informatik gibt, die von einem Computer mehr Funktionalität beansprucht als andere Probleme (und vielleicht sogar mehr als ein Computer prinzipiell haben kann), sollte Motivation genug sein, sich mit theoretischer Informatik auseinanderzusetzen.

\subsection{Deterministische Endliche Automaten}\label{sec:regular_dfa}
Wir beginnen mit der Art Automaten, die ``die einfachste`` Klasse formaler Sprachen erkennen kann.
\begin{definition}
	Ein \textit{deterministischer endlicher Automat (DFA)} (von engl.: deterministic finite automaton) ist ein 5-Tupel
	\[
		(Q, \Sigma, \delta, q_0, F),
	\]
	mit
	\begin{itemize}
		\item \( Q \) eine nicht-leere, endliche Menge von \textit{Zuständen},
		\item \( \Sigma \) ein nicht-leeres, endliches \textit{Eingabealphabet},
		\item \( \delta\colon Q \times \Sigma \to Q \) die \textit{Transitionsfunktion},
		\item \( q_0 \in Q \) der \textit{Startzustand},
		\item \(F \subseteq Q \) die Menge der \textit{akzeptierenden Zustände} (oder \textit{Endzustände}).
	\end{itemize}
\end{definition}
DFAs lassen sich auch problemlos als Strukturen wie in Abschnitt~\ref{sec:pre_structures} auffassen. Aus Gründen der Lesbarkeit verzichten wir jedoch darauf. Wir bezeichnen DFAs stets mit \( \mathcal{A}, \mathcal{B}, \ldots \), Zustände mit \( p, q, r, s \) und Variationen.\\
Es lassen sich auch durchaus noch einfacherere Rechenmodelle definieren (z.B. durch Restriktionen gegenüber der Größe der Zustandsmenge), dies ist jedoch vorerst nicht sinnvoll. Auf die bereits angesprochene Chomsky-Hierarchie werden wir noch genauer eingehen, aber auch dort sind die Sprachen, die durch DFAs erkannt werden können, als die einfachste Klasse bezeichnet.\\
Möchte man einen DFA konkret angeben, so ist die Darstellung als Transitionsgraph sinnvoller, als die Angabe des 5-Tupels.
\begin{definition}
	Sei \( \mathcal{A} = (Q, \Sigma, \delta, q_0, F) \) ein DFA. Der \textit{Transitionsgraph} von \( \mathcal{A} \) ein beschrifteter Graph \( G_\mathcal{A} = ((Q, E), \lambda, q_0, F) \) mit
	\[
		E = \{ (p, q) \mid \text{es ex. } a \in \Sigma \text{ mit } \delta(p, a) = q \}
	\]
	und
	\[
		\lambda\colon E \to 2^\Sigma, \quad (p, q) \mapsto \{ a \mid \delta(p, a) = q \}.
	\]
\end{definition}
Aus Gründen der Bequemlichkeit, lassen wir die Mengenklammern bei der Beschriftung der Transitionen weg. Der Startzustand \( q_0 \) bekommt einfach eine eingehende Kante ohne Beschriftung und ohne Startknoten. Die Endzustände werden zusätzlich eingekreist. Ein Beispieltransitionsgraph ist in Abbildung~\ref{fig:dfa_ex1}.
\begin{figure}
	\centering
	\input{figs/dfa_ex1}
	\caption{DFA für die Sprache aus Beispiel~\ref{exp:ex1}.}
	\label{fig:dfa_ex1}
\end{figure}
Wir werden die Begriffe Automat und Transitionsgraph gelegentlich synonym verwenden, da sich sowohl im Graphen als auch in der ursprünglichen Automatenstruktur alle Informationen befinden. Wir greifen dann auf den Begriff zurück, der für das aktuelle Thema die bequemere Anschauung hat.\\
Wir schauen uns nun das Verhalten eines DFA auf einem Wort an.
\begin{definition}
	Sei \( \mathcal{A} = (Q, \Sigma, \delta, q_0, F) \) ein DFA.
	Ein \textit{Lauf} von \( \mathcal{A} \) auf einem Wort \( w = a_0 \ldots a_{n-1} \) für ein \( n \in \mathbb{N} \) ist eine endliche Folge
	\[
		(r_0, a_0, r_1, a_1, \ldots, a_{n-1}, r_n),
	\]
	wobei \( r_0, \ldots, r_n \in Q \) und \( a_0, \ldots, a_{n-1} \in \Sigma \), sodass
	\begin{enumerate}
		\item \( r_0 = q_0 \),
		\item \( \delta(r_i, a_i) = r_{i+1} \) für \( i \in [n] \).
	\end{enumerate}
	Wir sagen ein Lauf ist \textit{akzeptierend}, wenn zusätzlich \( r_n \in F \) gilt.
\end{definition}
Wir bezeichnen Läufe in der Regel mit \( \varrho \) bzw. Variationen. Einen Lauf \( (r_0, a_0, r_1, a_1, \ldots, a_{n-1}, r_n) \) kürzen wir gelegentlich durch \( (r_0, r_1, \ldots, r_n) \) ab, wenn die Symbole nicht relevant für unsere Betrachtungen sind.
\begin{remark*}
	Zu jedem Wort \( w \in \Sigma^\ast \) existiert genau ein Lauf von \( \mathcal{A} \) auf \( w \).
\end{remark*}
\begin{definition}
\
	\begin{enumerate}
		\item Ein DFA \( \mathcal{A} = (Q, \Sigma, \delta, q_0, F) \) \textit{akzeptiert} ein Wort \( w \in \Sigma^\ast \), wenn der Lauf von \( \mathcal{A} \) akzeptierend ist. Andernfalls \textit{verwirft} \( \mathcal{A} \) das Wort \( w \).
		\item Die von einem DFA \( \mathcal{A} = (Q, \Sigma, \delta, q_0, F) \) \textit{erkannte Sprache} ist
			\[
				L(\mathcal{A}) \coloneqq \{ w \in \Sigma^\ast \mid \mathcal{A} \text{ akzeptiert } w \}.
			\]
		\item Eine Sprache \( L \) heißt \textit{DFA-erkennbar}, wenn es einen DFA \( \mathcal{A} \) gibt, sodass \( L = L(\mathcal{A}) \).
	\end{enumerate}
\end{definition}
\begin{example}\label{exp:ex1}
	Betrachte erneut den Automaten \( \mathcal{A} \) in Abbildung~\ref{fig:dfa_ex1}.
	\begin{itemize}
		\item Sei \( w_1 = abaaba \). Der Lauf von \( \mathcal{A} \) auf \( w_1 \) ist
			\[
				\varrho_1 = (q_0, q_1, q_2, q_1, q_1, q_2, q_1).
			\]
			D.h. \( \mathcal{A} \) akzeptiert \( w_1 \).
		\item Sei \( w_2 = baa \). Der Lauf von \( \mathcal{A} \) auf \( w_2 \) ist
			\[
				\varrho_2 = (q_0, q_3, q_3, q_3).
			\]
			D.h. \( \mathcal{A} \) verwirft \( w_2 \).
		\item \( \mathcal{A} \) erkennt die Sprache 
			\[
				L = \{ w \in \{a, b\}^\ast \mid w \text{ beginnt und endet mit } a \}.
			\]
	\end{itemize}
	Die letzte Aussage sagt etwas über das Verhalten des Automaten auf allen, d.h. unendlich vielen, Wörtern aus. Man kann also nicht für jedes Wort einzeln zeigen, dass sich der Automat korrekt verhält. Stattdessen beweisen wir die Aussage per Induktion.
	\begin{proof}
		Wir zeigen die folgende Aussage:
		\begin{center}
			\( \mathcal{A} \) akzeptiert das Wort \( w \) {g.d.w.} \( w \) beginnt und endet mit \( a \).				\end{center}
		Beweis per vollständige Induktion über Wortlänge \( n \in \mathbb{N} \). Ist \( r = (r_0, \ldots, r_n) \) der Lauf auf dem Wort \( w = a_0 \ldots a_{n-1} \), so ist
		\[
			r_n = \left\lbrace 
					\begin{array}{ll}
						q_0, & w = \varepsilon\\
						q_1, & a_0 = a_{n-1} = a\\
						q_2, & a_0 = a \text{ und } a_{n-1} = b\\
						q_3, & a_0 = b.
					\end{array}
				\right.
		\]
		Wir wollen also zeigen, dass ein Lauf von \( \mathcal{A} \) auf einem Wort dann und nur dann in \( q_1 \), dem einzigen akzeptierendem Zustand, endet, wenn \( w \) mit \( a \) beginnt und endet.\\
		Induktionsverankerung: \( n = 0 \). Dann ist \( w = \varepsilon \) und der Lauf von \( \mathcal{A} \) auf \( w \) ist \( r = (q_0) \), also auch \( r_n = r_0 = q_0 \).\checkmark\\
		Induktionshypothese (IH): Für \( w = a_0 \ldots a_{n-1} \) sei \( r = (r_0, \ldots, r_n) \) der Lauf auf \( \mathcal{A} \) mit \( r_n \) wie in der Behauptung.\\
		Induktionsschritt: Betrachte nun das Wort \( w = a_0 \ldots a_n \).
		\begin{itemize}
			\item \( a_0 \ldots a_{n-1} = \varepsilon \). Dann ist nach IH \( r_n = q_0 \) und somit
				\[
					r_{n+1} = \delta(r_n, a_n) = \left\lbrace
							\begin{array}{ll}
								q_1, & a_n = a\\
								q_3, & a_n = b.
							\end{array}
						\right.
				\]
			\item \( a_0 = a_{n-1} = a \). Dann ist nach IH \( r_n = q_1 \) und somit
				\[
					r_{n+1} = \delta(r_n, a_n) = \left\lbrace
							\begin{array}{ll}
								q_1, & a_n = a\\
								q_2, & a_n = b.
							\end{array}
						\right.
				\]
			\item \( a_0 = a \) und \( a_{n-1} = b \). Dann ist nach IH \( r_n = q_2 \) und somit
				\[
					r_{n+1} = \delta(r_n, a_n) = \left\lbrace
							\begin{array}{ll}
								q_1, & a_n = a\\
								q_2, & a_n = b.
							\end{array}
						\right.
				\]
			\item \( a_0 = b \). Dann ist nach IH \( r_n = q_3 \) und somit
				\[
					r_{n+1} = \delta(r_n, a_n) = q_3
				\]
				unabhängig von \( a_n \).
		\end{itemize}
		Insgesamt gilt also: 
		\begin{align*}
			% if you think this is ugly, I agree.
			w \text{ beginnt und endet mit } a. &\text{ g.d.w. } \text{Ist } r = (r_0, \ldots, r_n) \text{ der Lauf von }\\ &\quad\quad\quad\,\, \mathcal{A} \text{ auf } w \text{ so gilt } r_n = q_1 \in F.\\
			&\text{ g.d.w. } \mathcal{A} \text{ akzeptiert } w.\\
			&\text{ g.d.w. } L(\mathcal{A}) = L.
		\end{align*}
	\end{proof}
\end{example}
So ausführlich wie hier werden wir später nicht mehr beweisen, dass ein gegebener Automat ``das richtige tut``, sollte dies nicht klar sein werden wir die Funktionsweise nur grob erläutern. Ausführliche Beweise sind im Wesentlichen dann gefordert, wenn man zum Beispiel zeigen möchte, dass eine Sprache nicht DFA-erkennbar ist.


\subsection{Abschlusseigenschaften DFA-erkennbarer Sprachen}\label{sec:regular_closure}
Bei einer Einteilung aller möglichen Sprachen in Klassen will man in einer möglichst sinnvollen Weise vorgehen. Damit meint man u.a., dass die einzelnen Klassen in sich abgeschlossen sind bzgl. verschiedener Operationen oder auch andere Eigenschaften haben, die in einer wissenschaftlichen Weise ``schön`` sind. Die folgenden Abschnitte sind dazu da um zu zeigen, dass DFA-erkennbare Sprachen dies in vielerlei Hinsicht erfüllen. In diesem Abschnitt beginnen wir damit zu zeigen, dass DFA-erkennbare Sprachen unter den üblichen Mengenoperationen (Komplementbildung, Vereinigung und Schnitt) abgeschlossen sind. Im späteren Verlauf werden wir noch einige andere Operationen betrachten.\par
Wir zeigen als erstes, dass die DFA-erkennbaren Sprachen unter Komplementbildung abgeschlossen sind.
\begin{theorem}\label{thm:regular_complement}
	Sei \( L \subseteq \Sigma^\ast \) eine DFA-erkennbare Sprache. Dann ist auch \( \comp{L} \) DFA-erkennbar.
	\begin{proof}
		Sei \( L \subseteq \Sigma^\ast \) eine beliebige DFA-erkennbare Sprache. D.h. es existiert ein DFA \( \mathcal{A} = (Q, \Sigma, \delta, q_0, F) \), der \( L \) erkennt. Wir konstruieren aus \( \mathcal{A} \) den DFA
		\[
			\comp{\mathcal{A}} = (Q, \Sigma, \delta, q_0, Q \setminus F),
		\]
		welcher die Sprache \( \comp{L} \) erkennt. Die Konstruktion vertauscht also lediglich akzeptierende und nicht-akzeptierende Zustände. Wir müssen nun noch zeigen, dass diese Konstruktion korrekt ist, also formal, dass \( \comp{L(\mathcal{A})} = L(\comp{\mathcal{A}}) \) gilt. Dazu zeigen wir folgende Aussage, aus der offensichtlich die Behauptung folgt.
		\begin{center}
			Für alle \( w \in \Sigma^\ast \) gilt: \( \mathcal{A} \) akzeptiert \( w \) {g.d.w.} \( \comp{\mathcal{A}} \) verwirft \( w \).
		\end{center}
		Sei also \( w \in \Sigma^\ast \). Da \( \mathcal{A} \) und \( \comp{\mathcal{A}} \) den selben Startzustand \( q_0 \) und die selbe Transitionsfunktion \( \delta \) haben, haben beide Automaten den selben (eindeutigen) Lauf \( (r_0, \ldots, r_n) \) auf \( w \). \( \mathcal{A} \) akzeptiert \( w \) falls \( r_n \in F \). Dann gilt \( r_n \notin Q \setminus F \) und somit \( \comp{\mathcal{A}} \) verwirft \( w \). Die andere Richtung geht analog. Also gilt die Behauptung.
	\end{proof}
\end{theorem}
Diese Abschlusseigenschaft war einfach zu beweisen, da wir nur eine kleine Änderung am ursprünglichen DFA machen mussten und dann wieder einfach über den eindeutigen Lauf argumentieren konnten. Die Idee hinter der Konstruktion ist auch sehr intuitiv, da wir genau die Wörter akzeptieren wollen, die vom ursprünglichen Automaten verworfen wurden, also deren Läufe in nicht-akzeptierenden Zuständen enden. Der Ansatz die Zustände einfach zu vertauschen drängt sich also geradezu auf.\par
Für den Abschluss unter Vereinigung ist etwas mehr Arbeit zu machen. Wir haben also nun zwei DFA-erkennbare Sprachen (und damit die zugehörigen Automaten) und wollen nun prüfen ob ein Wort in wenigstens einer der beiden Sprachen liegt. Wir müssen nun also einen Automaten konstruieren, der zwei gegebene Automaten simuliert. Diese Simulation muss synchron bzw. parallel stattfinden, eine sequentielle (d.h. Hintereinander-) Ausführung beider Automaten ist nicht möglich (da DFAs bereits gelesene Symbole ``vergessen``, ein explizites ``Abspeichern`` ist nur möglich für konstant viele Symbole -- das reicht nicht für beliebig große Eingabelängen). Wir präsentieren für die parallele Ausführung nun die Produktkonstruktion im Rahmen des nächsten Satzes.
\begin{theorem}\label{thm:regular_union}
	Seien \( L_1, L_2 \subseteq \Sigma^\ast \) DFA-erkennbare Sprachen. Dann ist auch \( L_1 \cup L_2 \) DFA-erkennbar.
	\begin{proof}
		Seien \( \mathcal{A}_1 = (Q_1, \Sigma, \delta_1, q_0^1, F_1) \) und \( \mathcal{A}_1 = (Q_2, \Sigma, \delta_2, q_0^2, F_2) \) die DFAs für \( L_1, L_2 \). Wir betrachten den \textit{Produktautomaten}
		\[
			\mathcal{A} \coloneqq (Q_1 \times Q_2, \Sigma, \delta, (q_0^1, q_0^2), F)
		\]
		mit \( \delta((p, q), a) = (\delta_1(p, a), \delta_2(q, a)) \) für alle \( p \in Q_1, q \in Q_2, a \in \Sigma \) und \( F = (F_1 \times Q_2) \cup (Q_1 \times F_2) \).\\
		Wir zeigen nun, dass \( L(\mathcal{A}) = L(\mathcal{A}_1) \cup L(\mathcal{A}_2) \) ist.
		Sei dazu \( w = a_0 \ldots a_{n-1} \) gegeben. Wir zeigen, dass \( \mathcal{A} \) akzeptiert \( w \) {g.d.w.} \( \mathcal{A}_1 \) oder \( \mathcal{A}_2 \) das Wort \( w \) akzeptiert.\\
		``Wenn \( \mathcal{A}_1 \) oder \( \mathcal{A}_2 \) akzeptiert, dann akzeptiert \( \mathcal{A} \)``:
		{O.B.d.A.} sei \( \mathcal{A}_1 \) der Automat, der \( w \) akzeptiert. Es gibt also einen Lauf \( (r_0, \ldots, r_n) \) mit \( r_n \in F_1 \) von \( \mathcal{A}_1 \) auf \( w \). Sei \( (p_0, \ldots, p_n) \) der Lauf auf \( \mathcal{A}_2 \) mit \( p_n \) beliebig. Dann ist der Lauf auf auf \( \mathcal{A} \)
		\[
			((r_0, p_0), \ldots, (r_n, p_n)),
		\]
		da in jedem Schritt 
		\begin{align*}
			\delta((r_i, p_i), a_i) &= (\delta_1(r_i, a_i), \delta_2(p_i, a_i)) \\
			&= (r_{i+1}, p_{i+1}).
		\end{align*}
		Wegen \( r_n \in F_1 \) ist auch \( (r_n, p_n) \in F_1 \times Q_2 \subseteq F \). Also akzeptiert \( \mathcal{A} \).\\
		``Wenn \( \mathcal{A} \) akzeptiert, dann akzeptiert \( \mathcal{A}_1 \) oder \( \mathcal{A}_2 \)``:
		Wir zeigen die Kontraposition dieser Aussage. \( \mathcal{A}_1 \) und \( \mathcal{A}_2 \) verwerfen also beide. Die Läufe von \( \mathcal{A}_1, \mathcal{A}_2 \) sind also \( (r_0, \ldots, r_n) \) und \( (p_0, \ldots, p_n) \) mit \( r_n \notin F_1, p_n \notin F_2 \). Wie oben ist \( ((r_0, p_0), \ldots, (r_n, p_n)) \) der Lauf von \( \mathcal{A} \) und es gilt \( (r_n, p_n) \notin F \). Somit verwirft auch \( \mathcal{A} \) das Wort.
	\end{proof}
\end{theorem}
Eine Beispielkonstruktion für einen Produktautomaten für die Vereinigung zweier DFA-erkennbarer Sprachen befindet sich in Abbildung~\ref{fig:dfa_product}.
\begin{figure}
	\centering
	\input{figs/dfa_product}
	\caption{Produktkonstruktion: Der Automat \( \mathcal{A} \) erkennt die Sprache \( \{ w \in \{a, b \}^\ast \mid \left| w \right|_a + \left| w \right|_b \text{ teilbar durch } 3 \} \), \( \mathcal{B} \) erkennt die Sprache \( \{ ua : u \in \{a, b\}^\ast \} \). Der Produktautomat erkennt die Vereinigung.}
	\label{fig:dfa_product}
\end{figure}
Aus den Sätzen~\ref{thm:regular_complement} und~\ref{thm:regular_union} erhält man nun einfach alle übrigen Abschlusseigenschaften für die üblichen Mengenoperationen, aber auch mit der Produktkonstruktion lassen sich diese Eigenschaften zeigen.
\begin{corollary}
	Seien \( L_1, L_2 \) DFA-erkennbare Sprachen. Dann sind auch die Sprachen \( L_1 \cap L_2, L_1 \setminus L_2 \) DFA-erkannbar.
	\begin{proof}
		Wegen Satz~\ref{thm:regular_complement} sind auch \( \comp{L_1}, \comp{L_2} \) DFA-erkennbar und damit nach Satz~\ref{thm:regular_union} \( \comp{L_1} \cup \comp{L_2} \). Mit erneuter Anwendung von Satz~\ref{thm:regular_complement} ist auch \( \comp{\comp{L_1} \cup \comp{L_1}} \) DFA-erkennbar, was nach den DeMorgan'schen Gesetzen \( L_1 \cap L_2 \) entspricht. Alternativ kann man in der Produktkonstruktion auch \( F = F_1 \times F_2 \) setzen und erhält einen DFA für \( L_1 \cap L_2 \).\\
		Für \( L_1 \setminus L_2 \) setzt man \( F = F_1 \times (Q_2 \setminus F_2) \) und erhält einen DFA für die Sprache.
	\end{proof}
\end{corollary}
Die Produktkonstruktion ist eine sehr grundlegende Konstruktion, die in ähnlicher Form immer wieder Anwendungen findet. Wir können auch eigene Sprachoperatoren erfinden und DFA-erkennbare Sprachen daraufhin untersuchen ob sie abgeschlossen sind bzgl. dieser Operationen.
\begin{example}
	Seien \( L, K \subseteq \Sigma^\ast \). Wir definieren die Operation \textit{Perfect Shuffle} wie folgt:
	\[
		L \shuffle K \coloneqq \{ a_0 b_0 \ldots a_{n-1} b_{n-1} : a_0 \ldots a_{n-1} \in L, b_0 \ldots b_{n-1} \in K \}.
	\]
\end{example}
\begin{theorem}
	Seien \( L_1, L_2 \subseteq \Sigma^\ast \) DFA-erkennbare Sprachen. Dann ist auch \( L_1 \shuffle L_2 \) DFA-erkennbar.
	\begin{proof}
		Seien \( \mathcal{A}_1 = (Q_1, \Sigma, \delta_1, q_0^1, F_1), \mathcal{A}_2 = (Q_2, \Sigma, \delta_2, q_0^2, F_2) \) die DFAs für \( L_1, L_2 \). Wir definieren wieder einen Produktautomaten
		\[
			\mathcal{A} = (Q_1 \times Q_2 \times [2], \Sigma, \delta, (q_0^1, q_0^2, 0), F)
		\]
		mit
		\[
			\delta((p, q, i), a) = \left\lbrace
				\begin{array}{ll}
					(\delta_1(p, a), q, 1), & i = 0\\
					(p, \delta_2(q, a), 0), & i = 1
				\end{array}
			\right.
		\]
		und \( F = F_1 \times F_2 \times \{0\} \). Die Idee ist diesmal nur eine \textit{quasi-parallele} Simulation von \( \mathcal{A}_1 \) und \( \mathcal{A}_2 \). Die dritte Komponente des Zustands gibt an in welchem Automat \( \mathcal{A} \) den nächsten Schritt simulieren soll. Wir akzeptieren, wenn beide Simulationen in einem Endzustand sind und der zuletzt durchgeführte Simulationsschritt auf \( \mathcal{A}_2 \) war. Wir zeigen nun noch, dass die Konstruktion funktioniert.\\
		``\( L(\mathcal{A}) \subseteq L_1 \shuffle L_2 \)``: Sei \( w = c_0 \ldots c_{n-1} \in L(\mathcal{A}) \). D.h. es existiert ein Lauf 
		\[
			\varrho = ((p_0, q_0, i_0), \ldots, (p_n, q_n, i_n))
		\]
		von \( \mathcal{A} \) auf \( w \) mit \( p_n \in F_1, q_n \in F_2 \) und \( i_j = j \mod 2 \) und \( i_0 = i_n = 0 \) (insbesondere ist \( \left| w \right| \) gerade), wobei abwechselnd in jedem Schritt \( j \) die \( 1 + i_j \)te Komponenten gleich bleibt (s. Definition von \( \delta \)). Aus den geraden Positionen in \( \varrho \) (die mit der dritten Komponente \( 0 \)) ergeben dann einen Lauf von \( \mathcal{A}_1 \) auf dem Wort \( c_0 c_2 \ldots c_{n-2} \). Umgekehrt sind die ungeraden Positionen induziert durch den Lauf von \( \mathcal{A}_2 \) auf \( c_1 c_3 \ldots c_{n-1} \). Wegen \( p_n \in F_1 \) und \( i_n = 0 \) ist \( p_{n-1} = p_n \in F_1 \) und somit akzeptiert \( \mathcal{A}_1 \) das Wort \( c_0 c_2 \ldots c_{n-2} \). Analog für \( \mathcal{A}_2 \). Also ist \( w \in L(\mathcal{A}_1) \shuffle L(\mathcal{A}_2) \).\\
		``\( L(\mathcal{A}) \supseteq L_1 \shuffle L_2 \)``: Sei \( w = a_0 b_0 \ldots a_{n-1} b_{n-1} \in L_1 \shuffle L_2 \). Dann exitieren Läufe \( \varrho_1 = (p_0, \ldots, p_n), \varrho_2 = (q_0, \ldots, q_n) \) mit \( p_n \in F_1, q_n \in F_2 \) von \( \mathcal{A}_1, \mathcal{A}_2 \). Nach Definition von \( \delta \) ist der Lauf auf \( \mathcal{A} \) dann
		\[
			((p_0, q_0, 0), (p_1, q_0, 1), \ldots, (p_n, q_{n-1}, 1), (p_n, q_n, 0))
		\]
		und \( \mathcal{A} \) akzeptiert \( w \).
	\end{proof}
\end{theorem}


\subsection{Nichtdeterministische Endliche Automaten}\label{sec:regular_nfa}
Im letzten Abschnitt haben wir gesehen, dass unter einigen Operationen abgeschlossen sind. Die Mengenoperationen wirken dabei ohnehin von Vorteil für weitere Betrachtungen unter mathematischen Aspekten. Perfect Shuffle könnte man dagegen als eine Routine sehen, ob zum Beispiel ein Prozessor zwei Prozessen wirklich abwechselnd Berechnungszeit gibt. Wir würden gerne weitere Abschlusseigenschaften kennenlernen, besonders die Konkatenation unter der Kleene-Stern wären nun interessant. Eine simultane Ausführung zweier Automaten bringt hier jedoch nichts mehr, da beide Operationen eher von sequentieller Natur sind (Hintereinanderausführung, Wiederholung). DFAs sind für diese Aufgaben zunächst nicht sonderlich sinnvoll. Denkbar wäre ein Modell, dass nach Erreichen eines Endzustandes den nächsten Automaten (im Falle der Konkatenation) auf dem Rest des Wortes startet. Ein DFA weiß aber nicht ad hoc wie das Wort zerlegt ist, es kann also sein, dass nach Erreichen eines Endzustandes der erste Automat noch weiterlaufen soll und erst bei erneutem Besuch eines akzeptierenden Zustandes das zweite Wort losgeht. Zu diesem Zweck führen wir das Prinzip des Nichtdeterminismus ein. Ein Automat kann dann ``raten`` in welchen Zustand er wechseln soll (bzw. ob er ``den nächsten Automaten startet``). Dieses Konzept wirkt etwas unnatürlich, da es nicht von einem Computer simuliert werden kann (Zufall \( \neq \) Nichtdeterminismus!), in unserem Modell rät der Automat stets ``richtig``.
\begin{definition}
	Ein \textit{nicht-deterministischer endlicher Automat (NFA)} (von engl.: non-deterministic finite automaton) ist ein 5-Tupel
	\[
		(Q, \Sigma, \Delta, q_0, F),
	\]
	mit
	\begin{itemize}
		\item \( Q \) eine nicht-leere, endliche Menge von \textit{Zuständen},
		\item \( \Sigma \) ein nicht-leeres, endliches \textit{Eingabealphabet},
		\item \( \Delta \subseteq Q \times \Sigma \times Q \) die \textit{Transitionsrelation},
		\item \( q_0 \in Q \) der \textit{Startzustand},
		\item \(F \subseteq Q \) die Menge der \textit{akzeptierenden Zustände} (oder \textit{Endzustände}).
	\end{itemize}
\end{definition}
Wir bezeichnen NFAs genau wie DFAs mit \( \mathcal{A}, \mathcal{B} \) usw. Die Transitionsgraphen sehen ebenfalls genauso aus, nur, dass nun Zustände mehrere Kanten haben können, die gleich beschriftet sind. Außerdem ist es erlaubt, dass Transitionen komplett fehlen.
\begin{remark*}
	Eine äquivalente und ebenfalls verbreitete Definition benutzt statt einer Transitionsrelation wieder eine Transitionsfunktion \( \delta\colon Q \times \Sigma \to 2^Q \). 
\end{remark*}
\begin{remark*}
	Auch wenn es widersprüchlich klingt, aber jeder DFA kann auch als ein NFA gesehen werden. Genauer gesagt ist ein DFA ein NFA bei dem die Transitionsrelation der Graph einer totalen Funktion \( Q \times \Sigma \to Q \) ist.
\end{remark*}
Bisher ist noch nicht klar, wie das Akzeptanzverhalten von NFAs sein soll.
\begin{definition}
	Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) ein NFA.
	Ein \textit{Lauf} von \( \mathcal{A} \) auf einem Wort \( w = a_0 \ldots a_{n-1} \) für ein \( n \in \mathbb{N} \) ist eine endliche Folge
	\[
		(r_0, a_0, r_1, a_1, \ldots, a_{n-1}, r_n),
	\]
	wobei \( r_0, \ldots, r_n \in Q \) und \( a_0, \ldots, a_{n-1} \in \Sigma \), sodass
	\begin{enumerate}
		\item \( r_0 = q_0 \),
		\item Für alle \( i \in [n] \) gilt, dass \( (r_i, a_i, r_{i+1}) \in \Delta \).
	\end{enumerate}
	Wir sagen ein Lauf ist \textit{akzeptierend}, wenn zusätzlich \( r_n \in F \) gilt.
\end{definition}
\begin{remark*}
	Für NFAs müssen Läufe nicht mehr eindeutig sein. Es kann zu einem Wort mehrere Läufe geben oder auch gar keine Läufe, wenn entsprechende Transitionen fehlen.
\end{remark*}
\begin{definition}
\
	\begin{enumerate}
		\item Ein NFA \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) \textit{akzeptiert} ein Wort \( w \in \Sigma^\ast \), wenn es mindestens einen akzeptierenden Lauf von \( \mathcal{A} \) gibt. Andernfalls \textit{verwirft} \( \mathcal{A} \) das Wort \( w \).
		\item Die von einem NFA \( \mathcal{A} = (Q, \Sigma, \delta, q_0, F) \) \textit{erkannte Sprache} ist
			\[
				L(\mathcal{A}) \coloneqq \{ w \in \Sigma^\ast \mid \mathcal{A} \text{ akzeptiert } w \}.
			\]
		\item Eine Sprache \( L \) heißt \textit{NFA-erkennbar}, wenn es einen NFA \( \mathcal{A} \) gibt, sodass \( L = L(\mathcal{A}) \).
	\end{enumerate}
\end{definition}
\begin{example}\label{exp:ex2}
	Wir betrachten die Sprache
	\[
		L = \{ w \in \{a, b\}^\ast \mid \text{das vorletzte Symbol in } w \text{ ist } a \}.
	\]
	In Abbildung~\ref{fig:nfa_ex1} befindet sich ein DFA und ein NFA für die Sprache. Wir sehen, dass der NFA weniger Zustände hat. Dies ist nicht überraschen, denn der DFA muss sich stets das zuletzt gelesene Symbol im Zustand merken, während der NFA dies nicht muss und einfach ``rät`` welches Symbol das vorletzte ist.
\end{example}
\begin{figure}
	\centering
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/nfa_ex1dfa}
		\caption{DFA}
		\label{fig:nfa_ex1dfa}
	\end{subfigure}
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/nfa_ex1nfa}
		\caption{NFA}
		\label{fig:nfa_ex1nfa}
	\end{subfigure}
	\caption{Ein DFA und ein NFA für die Sprache aus Beispiel~\ref{exp:ex2}.}
	\label{fig:nfa_ex1}
\end{figure}
Für NFAs ist das \textit{Wortproblem}, das Problem ob ein Automat ein gegebenes Wort akzeptiert, nicht ganz so offensichtlich zu lösen wie für DFAs. Bei DFAs müssen wir lediglich die eindeutige Transitionsfolge anwenden und prüfen ob der letzte Zustand ein akzeptierender ist. Für NFAs können wir natürlich alle möglichen Läufe ausprobieren und prüfen, ob ein akzeptierender dabei ist. Doch es gieht effizienter mit der Erreichbarkeitsrelation.
\begin{definition}\label{def:reachability}
	Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) ein NFA und \( w = a_0 \ldots a_{n-1} \). Ein Zustand \( q \in Q \) heißt \textit{erreichbar} von \( p \) über \( w \) (geschrieben \( \mathcal{A}: p \reaches{w} q \)), wenn es einen Lauf \( (r_0, \ldots, r_n) \) gibt mit 
	\begin{itemize}
		\item \( r_0 = p, r_n = q \) und
		\item \( (r_i, a_i, r_{i+1}) \in \Delta \) für alle \( i \in [n] \).
	\end{itemize}
\end{definition}
Diese Notation können wir auch selbstverständlich auf DFAs anwenden. Wir lassen gelegentlich, dass \( \mathcal{A} \) weg, wenn der Automat aus dem Kontext klar ist.
\begin{definition}
	Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) ein NFA und \( w \in \Sigma^\ast \). Die \textit{Menge der in \( \mathcal{A} \) über \( w \) erreichbaren Zustände} ist definiert als
	\[
		E(\mathcal{A}, w) \coloneqq \{ q \in Q \mid \mathcal{A}: q_0 \reaches{w} q \}.
	\]
\end{definition}
Wir haben zwei Lemmata, die uns die Anwendung dieser Definition nahelegen.
\begin{lemma}\label{lem:reach1}
	Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F)\) ein NFA und \( w \in \Sigma^\ast \). \( w \in L(\mathcal{A}) \) {g.d.w.} \( E(\mathcal{A}, w) \cap F \neq \emptyset \).
	\begin{proof}
		``wenn, dann``: Sei \( w \in L(\mathcal{A}) \). Dann exitiert ein Lauf \( (r_0, \ldots, r_n) \) von \( \mathcal{A} \) auf \( w \) mit \( r_n \eqqcolon q \in F \), also \( q_0 \reaches{w} q \). Somit ist \( q \in E(\mathcal{A}, w) \). Also ist \( \emptyset \neq \{q\} \subseteq E(\mathcal{A}, w) \cap F \).\\
		``genau dann``: Es exitiert ein \( q \in E(\mathcal{A}, w) \cap F \), also \( q \in F \) und \( q \in E(\mathcal{A}, w) \). Also gibt es einen Lauf von \( \mathcal{A} \) auf \( w \), der in \( q_0 \) startet und in \( q \) endet. Dieser ist akzeptierend, also ist \( w \in L(\mathcal{A}) \).
	\end{proof}
\end{lemma}
\begin{lemma}\label{lem:reach2}
	Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) ein NFA.
	\begin{enumerate}
		\item \( E(\mathcal{A}, \varepsilon) = \{q_0\} \),
		\item Für alle \( u \in \Sigma^\ast \) und \( a \in \Sigma \) gilt
			\[
				E(\mathcal{A}, ua) = \bigcup_{p \in E(\mathcal{A}, u)} \{ q \in Q \mid (p, a, q) \in \Delta \}.
			\]
	\end{enumerate}
	\begin{proof}
		Induktionsverankerung: \( q \in E(\mathcal{A}, \varepsilon) \) {g.d.w.} \( q_0 \reaches{\varepsilon} q \) {g.d.w.} \( q = q_0 \). \checkmark\\
		Induktionsschritt: \( q \in E(\mathcal{A}, ua) \), also \( q_0 \reaches{ua} q \). Damit gibt es ein \( p \in Q \), sodass \( q_0 \reaches{u} p \reaches{a} q \). Wir folgern, dass \( p \in E(\mathcal{A}, u) \) und \( (p, a, q) \in \Delta \) und somit \( q \in \bigcup_{p \in E(\mathcal{A}, u)} \{ r \in Q \mid (p, a, r) \in \Delta \} \). Rückrichtung analog.
	\end{proof}
\end{lemma}
Mit Hilfe der Erreichbarkeitsrelation und Lemmata~\ref{lem:reach1} und~\ref{lem:reach2}, erhalten wir für das Wortproblem für NFAs einen Algorithmus.
\begin{algorithm}
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\underline{NFA-Akzeptanz}{$(\mathcal{A}, w)$}\\
	\Input{NFA $\mathcal{A}$, Wort $w$}
	\Output{Ja {g.d.w.} $\mathcal{A}$ akzeptiert $w = a_0 \ldots a_{n-1}$.}	
	$u \coloneqq \varepsilon$\\
	$E(\mathcal{A}, u) \coloneqq \{ q_0 \}$\\	
	\For{$i = 0, \ldots, n-1$}{
		Bestimme $E(\mathcal{A}, ua_i)$ aus $E(\mathcal{A}, u)$ (Lemma~\ref{lem:reach2})\\
		$u \coloneqq ua_i$
	}
	Prüfe, ob $E(\mathcal{A}, w) \cap F \neq \emptyset$.
	\caption{Wortproblem für NFAs}
	\label{alg:nfaacc}
\end{algorithm}
\begin{example}
	Wir betrachten erneut den NFA in Abbildung~\ref{fig:nfa_ex1nfa} und die Erreichbarkeitsmengen für die Präfixe von \( w = abbabaa \).
	\begin{align*}
		E(\mathcal{A}, \varepsilon) &= \{ q_0 \},\\
		E(\mathcal{A}, a) &= \{ q_0, q_1 \},\\
		E(\mathcal{A}, ab) &= \{ q_0, q_2 \},\\
		E(\mathcal{A}, abb) &= \{ q_0 \},\\
		E(\mathcal{A}, abba) &= \{ q_0, q_1 \},\\
		E(\mathcal{A}, abbab) &= \{ q_0, q_2 \},\\
		E(\mathcal{A}, abbaba) &= \{ q_0, q_1 \},\\
		E(\mathcal{A}, abbabaa) &= \{ q_0, q_1, q_2 \}.
	\end{align*}
	Wegen \( E(\mathcal{A}, w) \cap F \neq \emptyset \) wird \( w \) akzeptiert.
\end{example}


\subsection{Äquivalenz von NFAs und DFAs}\label{regular_equivalence}
Auf den ersten Blick wirkt es vermutlich so, dass NFAs ``mehr`` können als DFAs, da NFAs durch das stets richtige Raten der Transition einen Blick in die Zukunft werfen können. Dieser Abschnitt widmet sich jedoch der Äquivalenz von NFAs und DFAs, d.h. auch wenn wie in Beispiel~\ref{exp:ex2} NFAs mit weniger Zuständen die gleichen Sprachen erkennen können wie DFAs, so können auch DFAs jede NFA-erkennbare Sprache erkennen. Dies ist mit einer einfachen Überlegung auch gar nicht so unintuitiv: Die Erreichbarkeitsmenge für einen NFA und ein Wort ist stets endlich, da auch ein NFA lediglich endlich viele Zustände hat. In einer Simulation eines NFA in einem DFA könnte man also also einen Zustand durch die Menge der erreichbaren Zustände wählen und würde endlich bleiben. Details dazu folgen in diesem Abschnitt.
\begin{definition}\label{def:fa_equivalence}
	Seien \( \mathcal{A}, \mathcal{B} \) zwei endliche Automaten (deterministisch oder nicht-deterministisch). \( \mathcal{A} \) und \( \mathcal{B} \) heißen \textit{äquivalent}, wenn \( L(\mathcal{A}) = L(\mathcal{B}) \).
\end{definition}
Eine Bemerkung aus dem vorigen Abschnitt greifen wir nochmal im folgendem Lemma auf.
\begin{lemma}\label{lem:dfa2nfa}
	Zu jedem DFA exitiert ein äquivalenter NFA.
	\begin{proof}
		Sei \( \mathcal{A} = (Q, \Sigma, \delta, q_0, F) \) ein DFA. Wir definieren einen NFA
		\[
			\mathcal{A}^\prime = (Q, \Sigma, \Delta, q_0, F),
		\]
		mit \( \Delta = \{ (p, a, q) \mid \delta(p, a) = q \} \). Wir zeigen, dass \( \mathcal{A}^\prime \) und \( \mathcal{A} \) äquivalent sind. Dazu sei \( w = a_0 \ldots a_{n-1} \in L(\mathcal{A}) \). Also ist der eindeutige Lauf \( \varrho = (r_0, \ldots, r_n) \) akzeptierend auf \( \mathcal{A} \). Der Lauf ist nach Konstruktion auch ein Lauf auf \( \mathcal{A}^\prime \), also akzeptiert auch \( \mathcal{A}^\prime \). Rückrichtung analog.
	\end{proof}
\end{lemma}
Diese Richtung war relativ einfach mit den eingangs genannten Bemerkungen. Man könnte den Beweis auch aufwändig wieder über Induktion führen, dies ist aber nicht sinnvoll, da das Ergbenis recht klar ist.
\begin{lemma}\label{lem:nfa2dfa}
	Zu jedem NFA existiert ein äquivalenter DFA.
	\begin{proof}
		Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) ein NFA. Wir konstruieren einen DFA, der äquivalent ist, durch die sogenannte \textit{Potenzmengenkonstruktion}:
		\[
			\mathcal{A}^\prime = (2^Q, \Sigma, \delta, \{q_0\}, \{ P \subseteq Q \mid P \cap F \neq \emptyset \})
		\]
		mit \( \delta(P, a) = \{ q \mid \text{es ex. } p \in P \text{ mit } (p, a, q) \in \Delta \} \).
		Wir zeigen, dass beide Automaten äquivalent sind durch die Behauptung, dass für alle \( w \in \Sigma^\ast \) und \( P \subseteq Q \) mit \( \mathcal{A}^\prime: \{q_0\} \reaches{w} P \) gilt, dass \( P = E(\mathcal{A}, w) \), d.h. der Zustand, den der Potenzmengenautomatauf dem Wort \( w \) erreicht, entspricht der Erreichbarkeitsmenge auf dem selben Wort für den NFA. Dies zeigen wir per Induktion über alle Wortlängen \( n \).\\
		Induktionsverankerung: \( n = 0 \). Dann ist \( w = \varepsilon \) und es gilt \( P = \{q_0\} = E(\mathcal{A}, \varepsilon) \) nach Lemma~\ref{lem:reach2}.\\
		Induktionsschritt: \( n \rightarrow {n+1} \). Dann ist \( w = ua \) für ein \( u \in \Sigma^n \) und \( a \in \Sigma \). Sei \( P^\prime \subseteq Q \), sodass \( \mathcal{A}^\prime: \{q_0\} \reaches{u} P^\prime \). Nach Induktionshypothese ist \( P^\prime = E(\mathcal{A}, u) \). Somit gilt
		\begin{align*}
			P &= \delta(P^\prime, a)\\
			&= \{q \in Q \mid \text{es ex. } p \in P^\prime \text{ mit } (p, a, q) \in \Delta\}\\
			&= \bigcup_{p \in P^\prime = E(\mathcal{A}, u)} \{q \in Q \mid (p, a, q) \in \Delta\}\\
			&= E(\mathcal{A}, w)
		\end{align*}
		nach Definition von \( \delta \) und Lemma~\ref{lem:reach2}. Insgesamt gilt also, dass \( w \in L(\mathcal{A}) \) {g.d.w.} \( E(\mathcal{A}, w) \cap F \neq \emptyset \) (Lemma~\ref{lem:reach1}). Nach der oben gezeigten Behauptung gilt dies {g.d.w.} \( P \cap F \neq \emptyset \) und nach Definition des Konstruktion ist \( P \) genau dann akzeptierend im Potenzmengenautomaten. Somit akzeptiert \( \mathcal{A}^\prime \) das Wort \( w \).
	\end{proof}
\end{lemma}
In der Potenzmengenkonstruktion haben wir als Zustandsmenge stets die Potenzmenge der Zustandsmenge des NFA genutzt. Offenbar ist es aber so, dass dann einige Zustände unerreichbar sind, diese können auch weggelassen werden.
\begin{definition}\label{def:reduced_automaton}
	Sei \( \mathcal{A} = (Q, \Sigma, \frac{\delta}{\Delta}, q_0, F) \) ein DFA bzw. NFA.
	\begin{enumerate}
		\item Ein Zustand \( q \in Q \) ist \textit{erreichbar}, wenn es ein \( w \in \Sigma^\ast \) gibt, sodass \( \mathcal{A}: q_0 \reaches{w} q \).
		\item Der \textit{reduzierte Automat} (auf die erreicharen Zustände) ist:
			\[
				\mathcal{A}^\prime = (Q^\prime, \Sigma, \frac{\delta^\prime}{\Delta^\prime}, q_0, F^\prime)
			\]
			wobei
			\begin{itemize}
				\item \( Q^\prime \coloneqq \{ q \in Q \mid q \text{ erreichbar} \} \),
				\item \( \delta^\prime \coloneqq \left. \delta \right|_{Q^\prime \times \Sigma} \) bzw. \( \Delta^\prime \coloneqq \Delta \cap (Q^\prime \times \Sigma \times Q^\prime) \),
				\item \( F^\prime \coloneqq F \cap Q^\prime\).
			\end{itemize}
	\end{enumerate}
\end{definition}
Wir verwenden die Potenzmengenkonstruktion aus Lemma~\ref{lem:nfa2dfa} zur Determinisierung eines NFA. Wir können dabei schrittweise vom Anfangszustand die Zustände und Transitionen konstruieren um so direkt auf einen reduzierten Automaten gemäß Definition~\ref{def:reduced_automaton} zu kommen. Dies ist in Algorithmus~\ref{alg:nfa2dfa} beschrieben.
\begin{algorithm}
	\SetKwInOut{Input}{Input}
	\SetKwInOut{Output}{Output}
	\underline{Potenzmengenkonstruktion}{$(\mathcal{A})$}\\
	\Input{NFA $\mathcal{A} = (Q, \Sigma, \Delta, q_0, F)$}
	\Output{äquivalenter, reduzierter DFA $\mathcal{A}^\prime = (Q^\prime, \Sigma, \delta, q_0^\prime, F^\prime)$}	
	$Q^\prime \coloneqq \{\{q_0\}\}$\\
	$q_0^\prime \coloneqq \{q_0\}$\\
	$F^\prime \coloneqq \emptyset$\\
	Queue $P \coloneqq Q^\prime$\\
	\While{$P \neq \emptyset$}{
		$S \coloneqq P$.dequeue()\\
		\For{$a \in \Sigma$}{
			$R \coloneqq \{\bigcup_{p \in S} \{ r \mid (p, a, r) \in \Delta \}$\\
			$P$.enqueue($R$)\\
			$Q^\prime \coloneqq Q^\prime \cup R$\\
			$\delta(S, a) = R$
		}
	}
	\For{$P \in Q^\prime$}{
		\uIf{$P \cap F \neq \emptyset$}{
			$F^\prime \coloneqq F^\prime \cup \{ P \}$
		}
	}
	
	\caption{NFA-Determinisierung}
	\label{alg:nfa2dfa}
\end{algorithm}
\begin{example}
	Wir betrachten den NFA in Abbildung~\ref{fig:powersetconstruction_nfa}. In Abbildung~\ref{fig:powersetconstruction_dfa} ist ein äquivalenter, reduzierter DFA, erhalten durch Potenzmengenkonstruktion.
\end{example}
\begin{figure}
	\centering
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/powersetconstruction_nfa}
		\caption{NFA}
		\label{fig:powersetconstruction_nfa}
	\end{subfigure}\\
	\ \\
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/powersetconstruction_dfa}
		\caption{Potenzmengenautomat}
		\label{fig:powersetconstruction_dfa}
	\end{subfigure}
	\caption{Beispiel zur Potenzmengenkonstruktion.}
	\label{fig:powersetconstruction}
\end{figure}
\begin{theorem}
	Eine Sprache ist genau dann DFA-erkennbar, wenn sie NFA-erkennbar ist.
	\begin{proof}
		Die Lemmata~\ref{lem:dfa2nfa} und~\ref{lem:nfa2dfa} zusammen geben den Beweis.
	\end{proof}
\end{theorem}
In diesem Sinne ist es sinnvoll von nun an nur noch von FA-erkennbaren Sprachen zu sprechen statt zwischen DFA- und NFA-erkennbaren Sprachen zu unterscheiden.


\subsection[NFAs mit $\varepsilon$-Transitionen]{NFAs mit $\bm{\varepsilon}$-Transitionen}
Mit Blick auf spätere Abschnitte erweitern wir das Modell der NFAs um die Möglickeit den Zustand zu wechseln ohne ein Symbol dabei zu lesen.
\begin{definition}
	Ein \textit{nicht-deterministischer endlicher Automat mit} \textit{\(\varepsilon\)-Transitionen (\(\varepsilon\)-NFA)} ist ein 5-Tupel
	\[
		(Q, \Sigma, \Delta, q_0, F),
	\]
	mit
	\begin{itemize}
		\item \( Q \) eine nicht-leere, endliche Menge von \textit{Zuständen},
		\item \( \Sigma \) ein nicht-leeres, endliches \textit{Eingabealphabet},
		\item \( \Delta \subseteq Q \times (\Sigma \cup \{\varepsilon\}) \times Q \) die \textit{Transitionsrelation},
		\item \( q_0 \in Q \) der \textit{Startzustand},
		\item \(F \subseteq Q \) die Menge der \textit{akzeptierenden Zustände} (oder \textit{Endzustände}).
	\end{itemize}
\end{definition}
Wir bezeichnen \(\varepsilon\)-NFAs wieder mit \( \mathcal{A}, \mathcal{B} \) usw. Transitionsgraphen lassen sich ebenfalls analog zeichnen wie für NFAs und DFAs, wobei \(\varepsilon\)-Transitionen durch Kanten gekennzeichnet werden, die mit \( \varepsilon \) beschriftet sind. Der Voll\-stän\-dig\-keit halber definieren wir auch wieder Läufe auf \(\varepsilon\)-NFAs und das Akzeptanzverhalten.
\begin{definition}
	Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) ein \(\varepsilon\)-NFA.
	Ein \textit{Lauf} von \( \mathcal{A} \) auf einem Wort \( w = a_0 \ldots a_{n-1} \) für ein \( n \in \mathbb{N} \) ist eine endliche Folge
	\[
		(r_0, \sigma_0, r_1, \sigma_1, \ldots, sigma_{m-1}, r_m),
	\]
	wobei \( r_0, \ldots, r_m \in Q \) und \( \sigma_0, \ldots, \sigma_{m-1} \in \Sigma \cup \{\varepsilon\} \), sodass
	\begin{enumerate}
		\item \( r_0 = q_0 \),
		\item Für alle \( i \in [m] \) gilt, dass \( (r_i, \sigma_i, r_{i+1}) \in \Delta \).
	\end{enumerate}
	Wir sagen ein Lauf ist \textit{akzeptierend}, wenn zusätzlich \( r_n \in F \) gilt.
\end{definition}
\begin{definition}
\
	\begin{enumerate}
		\item Ein \(\varepsilon\)-NFA \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) \textit{akzeptiert} ein Wort \( w \in \Sigma^\ast \), wenn es mindestens einen akzeptierenden Lauf von \( \mathcal{A} \) gibt. Andernfalls \textit{verwirft} \( \mathcal{A} \) das Wort \( w \).
		\item Die von einem \(\varepsilon\)-NFA \( \mathcal{A} = (Q, \Sigma, \delta, q_0, F) \) \textit{erkannte Sprache} ist
			\[
				L(\mathcal{A}) \coloneqq \{ w \in \Sigma^\ast \mid \mathcal{A} \text{ akzeptiert } w \}.
			\]
		\item Eine Sprache \( L \) heißt \textit{\(\varepsilon\)-NFA-erkennbar}, wenn es einen \(\varepsilon\)-NFA \( \mathcal{A} \) gibt, sodass \( L = L(\mathcal{A}) \).
	\end{enumerate}
\end{definition}
\begin{example}\label{exp:ex3}
	Wir betrachten die Sprache \( L = \{ a^n b^m : n, m \in \mathbb{N} \} \cup \{ a^n c^m : n, m \in \mathbb{N} \} \). Der \(\varepsilon\)-NFA in Abbildung~\ref{fig:epsnfa_ex1} erkennt die Sprache \( L \) mit drei Zuständen.
\end{example}
\begin{figure}
	\centering
	\input{figs/epsnfa_ex1}
	\caption{\(\varepsilon\)-NFA, der die Sprache aus Beispiel~\ref{exp:ex3} erkennt.}
	\label{fig:epsnfa_ex1}
\end{figure}
Für \(\varepsilon\)-NFAs zeigen wir wie im vorigen Abschnitt, dass auch sie die Klasse der FA-erkennbaren Sprachen nicht vergrößern. Der Äquivalenzbegriff aus Definition~\ref{def:fa_equivalence} überträgt sich natürlich auf \(\varepsilon\)-NFAs.
\begin{lemma}
	Zu jedem NFA existiert ein äquivalenter \(\varepsilon\)-NFA.
	\begin{proof}
		Dies ist sofort klar, da jeder NFA als ein \(\varepsilon\)-NFA betrachtet werden kann, der keine \(\varepsilon\)-Transitionen besitzt.
	\end{proof}
\end{lemma}
Bevor wir den anderen Teil der Äquivalenz zeigen fehlt uns eine Definition.
\begin{definition}
	Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) ein \(\varepsilon\)-NFA. Der \textit{\(\varepsilon\)-Abschluss} (auch \(\varepsilon\)-Hülle) eines Zustands \( p \in Q \) ist
	\[
		\comp{\varepsilon}(p) \coloneqq \{ q \in Q \mid \text{es ex. } p_1, \ldots, p_k \text{ mit } (p, \varepsilon, p_1), (p_i, \varepsilon, p_{i+1}), (p_k, \varepsilon, q) \in \Delta \}.
	\]
	Für Mengen \( P \subseteq Q \) ist der \textit{\(\varepsilon\)-Abschluss} dann erweitert durch
	\[
		\comp{\varepsilon}(P) \coloneqq \bigcup_{p \in P} \comp{\varepsilon}(p).
	\]
\end{definition}
Auf diese Weise lässt sich die Erreichbarkeitsrelation, die wir schon aus Definition~\ref{def:reachability} kennen erweitern.
\begin{definition}
	Sei \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) ein NFA und \( w = a_0 \ldots a_{n-1} \). Ein Zustand \( q \in Q \) heißt \textit{erreichbar} von \( p \) über \( w \) (geschrieben \( \mathcal{A}: p \reaches{w} q \)), wenn es ein \( m \geq n \), Indizes \( 0 \leq i_0 < \ldots < i_{n-1} \leq m \) und Zustände \( r_0, \ldots, r_m \in Q \) gibt, sodass
	\begin{itemize}
		\item \( r_0 = p, r_m = q \),
		\item \( (r_{i_j}, a_j, r_{i_j+1}) \in \Delta \) für alle \( j \in [n] \) und
		\item \( (r_i, \varepsilon, r_{i+1}) \in \Delta \) für alle \( i \in [m] \setminus \{i_1, \ldots, i_{n-1}\} \).
	\end{itemize}
\end{definition}
Man beachte, dass \( p \reaches{\varepsilon} q \) nicht \( p = q \) bedeutet wie bei NFAs.
\begin{lemma}\label{lem:epsnfa2nfa}
	Zu jedem \(\varepsilon\)-NFA existiert ein äquivalenter NFA.
	\begin{proof}
		Wir betrachten einen \(\varepsilon\)-NFA \( \mathcal{A} = (Q, \Sigma, \Delta, q_0, F) \) und überführen ihn in einen äquivalenten NFA \( \mathcal{A}^\prime = (Q, \Sigma, \Delta^\prime, q_0, F^\prime) \). Dabei ist
		\[
			\Delta^\prime \coloneqq \{(p, a, q) \in Q \times \Sigma \times Q \mid \mathcal{A}: p \reaches{a} q\}
		\]
		und \( F^\prime \coloneqq \{q \in Q \mid q \in \comp{\varepsilon}(F)\} \).
		%TODO Korrektheit
	\end{proof}
\end{lemma}
\begin{example}
	Wir betrachten den \(\varepsilon\)-NFA in Abbildung~\ref{fig:epsnfa_ex2_eps}. In Abbildung~\ref{fig:epsnfa_ex2_noeps} sehen wir den NFA den wir nach Lemma~\ref{lem:epsnfa2nfa} erhalten, wobei die neu eingefügten Transitionen rot markiert sind. Beachte auch, dass sich die Menge der akzeptierenden Zustände geändert hat, da sonst das leere Wort nicht mehr akzeptiert werden würde.
\end{example}
\begin{figure}
	\centering
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/epsnfa_ex2_eps}
		\caption{mit \(\varepsilon\)-Transitionen}
		\label{fig:epsnfa_ex2_eps}
	\end{subfigure}~
	\begin{subfigure}[b]{.49\textwidth}
		\centering
		\input{figs/epsnfa_ex2_noeps}
		\caption{ohne \(\varepsilon\)-Transitionen}
		\label{fig:epsnfa_ex2_noeps}
	\end{subfigure}
	\caption{Eliminieren von \(\varepsilon\)-Transitionen}
	\label{fig:epsnfa_ex2}
\end{figure}
\begin{remark*}
	Beachte, dass ein Zusammenziehen der Zustände, die durch \(\varepsilon\)-Transitionen verbunden sind nicht funktioniert, da das im Allgemeinen die erkannte Sprache verändert. Ein solches Vorgehen würde zum Beispiel dazu führen, dass der entstehende Automat zu Beispiel~\ref{fig:epsnfa_ex1} nur noch einen Zustand besitzt mit einem durch \( a, b, c \) beschrifteten Loop. Die erkannte Sprache wäre dann \( \{a, b, c\}^\ast \).
\end{remark*}
\begin{corollary}
	Zu jedem \(\varepsilon\)-NFA existiert ein äquivalenter DFA.
	\begin{proof}
		Lemma~\ref{lem:epsnfa2nfa} liefert zunächst einen NFA, der mit Lemma~\ref{lem:nfa2dfa} in einen DFA umgewandelt werden kann.
	\end{proof}
\end{corollary}
Wir werden also auch weiterhin von FA-erkennbaren Sprachen sprechen, solange sie von einem DFA, NFA oder \(\varepsilon\)-NFA erkannt werden, da alle drei Modelle gleich mächtig sind. In mancher Fachliteratur wird wegen ihrer Äqui\-va\-lenz auch zwischen NFAs und \(\varepsilon\)-NFAs gar nicht unterschieden -- wir werden im Folgenden die Unterscheidung dennoch weiterhin machen.


\subsection{Reguläre Ausdrücke}\label{sec:regular_regexp}
Bisher haben wir Sprachen betrachtet, die sich von endlichen Automaten erkennen lassen. Diese Art von Sprachen liefern uns eine eigene Klasse von Sprachen, die unter verschiedenen Operationen abgeschlossen ist. Auch wenn bisher noch nicht alles gezeigt wurde (Konkatenation, Kleene'sche Hülle) lässt sich mit einiger Berechtigung sagen, dass die Klasse der FA-erkennbaren Sprachen gute Eigenschaften hat. Wir untersuchen nun welche Sprache wir mit sogenannten \textit{regulären Ausdrücken} beschreiben können.
\begin{definition}\label{def:regexsyntax}
	Sei \( \Sigma \) ein endliches Alphabet. Ein \textit{regulärer Ausdruck} ist induktiv definiert mit:
	\begin{itemize}
		\item \( \bm{\emptyset} \) ist ein regulärer Ausdruck.
		\item Für jedes \( a \in \Sigma \) ist \( \bm{a} \) ein regulärer Ausdruck.
		\item Falls \( r, r^\prime \) reguläre Ausdrücke sind, dann ist auch \( (r \bm{+} r^\prime) \) ein regulärer Ausdruck.
		\item Falls \( r, r^\prime \) reguläre Ausdrücke sind, dann ist auch \( (r \bm{\cdot} r^\prime) \) ein regulärer Ausdruck.
		\item Falls \( r \) reguläre Ausdrücke sind, dann ist auch \( r \overset{\bm{\ast}}{} \) ein regulärer Ausdruck.
	\end{itemize}
	Die \textit{Menge aller regulären Ausdrücke} über \( \Sigma \) bezeichnen mit \( \mathsf{RE}_\Sigma \).
\end{definition}
Das ist bisher lediglich die Syntax der regulären Ausdrücke gewesen. Nun definieren wir eine Sematik für diese Ausdrücke, d.h. wir ordnen jedem regulären Ausdruck eine Sprache zu.
\begin{definition}
	Sei \( \Sigma \) ein endliches Alphabet. Die \textit{Interpretation eines regulären Ausdrucks} ist die Abbildung
	\[
		\llbracket \cdot \rrbracket \colon \mathsf{RE}_\Sigma \to 2^{\Sigma^\ast}
	\]
	mit
	\begin{itemize}
		\item \( \llbracket \bm{\emptyset} \rrbracket = \emptyset \),
		\item \( \llbracket \bm{a} \rrbracket = \{ a \} \) für jedes \( \bm{a} \in \mathsf{RE}_\Sigma \),
		\item \( \llbracket (r \bm{+} r^\prime) \rrbracket = \llbracket r \rrbracket \cup \llbracket r^\prime \rrbracket \),
		\item \( \llbracket (r \bm{\cdot} r^\prime) \rrbracket = \llbracket r \rrbracket \cdot \llbracket r^\prime \rrbracket \),
		\item \( \llbracket r \overset{\bm{\ast}}{} \rrbracket = \llbracket r \rrbracket^\ast \).
	\end{itemize}
	Eine Sprache \( L \subseteq \Sigma^\ast \) heißt \textit{regulär}, wenn ein regulärer Ausdruck \( r \in \mathsf{RE}_\Sigma \) existiert mit \( \llbracket r \rrbracket = L \).
\end{definition}
Wir erlauben in der Regel auch als Abkürzung die Ausdrücke \( \bm{\varepsilon} \) für \( \bm{\emptyset} \overset{\bm{\ast}}{} \) und \( r \overset{\bm{+}}{} \) für \( r \bm{\cdot} r \overset{\bm{\ast}}{} \). Außerdem lassen wir den Punkt (\( \bm{\cdot} \)) weg, es sei denn er dient der Lesbarkeit. Die Klammern können wir auch weglassen unter der Konvention, dass \( \overset{\bm{\ast}}{} \) stärker bindet als \( \bm{\cdot} \), was wiederum stärker bindet als \( \bm{+} \). Statt \( \llbracket r \rrbracket \) ist auch die Schreibweise \( L(r) \) gebräuchlich.\par
Reguläre Ausdrücke kennt man auch für Computerprogramme wie \texttt{grep}, \texttt{awk} oder \texttt{sed}. Diese sind syntaktisch etwas anders aufgebaut, jedoch lässt sich jeder POSIX-Ausdruck (das sind die regulären Ausdrücke für oben genannte Programme) auch als regulärer Ausdruck wie in Definition~\ref{def:regexsyntax} umschreiben.
\begin{example}
	Die POSIX-Syntax für reguläre Ausdrücke geht wie folgt.
	\begin{itemize}
		\item \( r \)\verb$|$\( r^\prime \) für \( r \bm{+} r^\prime \),
		\item Für \( (\bm{a + b +} \ldots \bm{+ z}) \) geht auch \verb$[a-z]$\\
			(analog: \verb$[A-Z]$,  \verb$[0-9]$, \verb$[a-z0-9,\.:;\?!]$ usw.),
		\item \verb$.$ für ein beliebiges Zeichen,
		\item \( r \)\verb$?$ für \( r \bm{+ \varepsilon} \),
		\item \( r \)\verb$+$ und \( r \)\verb$*$ für \( r\overset{\bm{+}}{}, r\overset{\bm{\ast}}{} \),
		\item \( r \)\verb${m,n}$ für \( r^m \bm{+} r^{m+1} \bm{+} \ldots \bm{+} r^n \).
	\end{itemize}
	Wir können zum Beispiel die Sprache aller E-Mail-Adressen als Ausdruck
	\[
		\verb$[a-zA-Z0-9\.-]+@[a-zA-Z0-9\.-]+\.(de|com|net)$
	\]
	darstellen.
\end{example}
Für unsere Analyse von regulären Sprachen benutzen wir nur reguläre Ausdrücke der Form wie in Definition~\ref{def:regexsyntax} vorgestellt. Dadurch lassen sich viele Beweise über den minimalistischen induktiven Aufbau der Ausdrücke führen.
\begin{example}
	Wir betrachten das Alphabet \( \Sigma = \{a, b\} \).
	\begin{itemize}
		\item \( L(\bm{((a+b)(a+b))} \overset{\bm{\ast}}{}) = \{ w \in \Sigma^\ast \mid \left| w \right| \text{ gerade} \} \).
		\item \( L(\bm{(a+b)(a+b)(a+b)} \overset{\bm{\ast}}{}) = \{ w \in \Sigma^\ast \mid \left| w \right| \geq 2 \} \).
		\item \( L(\bm{a} \overset{\bm{\ast}}{} \bm{+ b} \overset{\bm{\ast}}{}) = \{ w \in \Sigma^\ast \mid \left| w \right|_a = 0 \text{ oder } \left| w \right|_b = 0 \} \).
	\end{itemize}
\end{example}
Aus Gründen der Einfachheit werden wir von nun an bei der Notation von regulären Ausdrücken auf eine Unterscheidung zu Alphabetsymbolen, Kleene-Stern usw. verzichten, d.h. wir verwenden \( \emptyset, \varepsilon, a, +, \cdot, ^\ast \) statt \( \bm{\emptyset}, \bm{\varepsilon}, \bm{a}, \bm{+}, \bm{\cdot}, \overset{\bm{\ast}}{} \). Außerdem verwenden wir Shortcuts, z.B. \( \sum_{a\in\Sigma} a = \Sigma^\ast \). Formal ist aber wichtig weiterhin eine Unterscheidung zwischen Sprachen und regulären Ausdrücken zu haben.
\begin{definition}
	Zwei reguläre Ausdrücke \( r, e \in \mathsf{RE}_\Sigma \) heißen \textit{äquivalent} (geschrieben \( r \equiv e \)), wenn \( \llbracket r \rrbracket = \llbracket e \rrbracket \).\\
	Ein regulärer Ausdruck \( r \in \mathsf{RE}_\Sigma \) und ein endlicher Automat \( \mathcal{A} \) (DFA, NFA) heißen \textit{äquivalent}, wenn  \( \llbracket r \rrbracket = L(\mathcal{A}) \).
\end{definition}
\begin{example}
	Die regulären Ausdrücke \( (a + b)^\ast \) und \( (a^\ast b^\ast)^\ast \) sind äquivalent.
\end{example}
Wir kommen nun zu einem der wichtigsten Ergebnisse der Automatentheorie und dieser Vorlesung.
\begin{theorem}[Äquivalenzsatz von Kleene]\label{thm:kleene_equivalence}
	Eine Sprache ist genau dann regulär, wenn sie FA-erkennbar ist.
\end{theorem}
Aus Gründen der Übersichtlichkeit werden wir den Beweis des Satzes aufteilen auf zwei Lemmata.
\begin{lemma}
	Jede reguläre Sprache ist FA-erkennbar.
	\begin{proof}
		Wir stellen im Rahmen dieses Beweises eine Variante der sogenannten Thompson-Konstruktion vor, die einen regulären Ausdruck in einen äquivalenten \( \varepsilon \)-NFA umwandelt. Die Konstruktion nutzt den induktiven Aufbau von regulären Ausdrücken aus.\\
		Basisfälle:
		\begin{figure}[h]
			\centering
			\begin{subfigure}[b]{.25\textwidth}
				\centering
				\input{figs/thompson_empty}
				\caption{\( r = \emptyset \)}
				\label{fig:thompson_empty}
			\end{subfigure}~
			\begin{subfigure}[b]{.25\textwidth}
				\centering
				\input{figs/thompson_eps}
				\caption{\( r = \varepsilon \)}
				\label{fig:thompson_eps}
			\end{subfigure}~
			\begin{subfigure}[b]{.4\textwidth}
				\centering
				\input{figs/thompson_symbol}
				\caption{\( r = a \)}
				\label{fig:thompson_symbol}
			\end{subfigure}
			\caption{Basisfälle der Thompson-Konstruktion}
			\label{fig:thompson_basic}
		\end{figure}\\
		Rekursive Fälle:
		\begin{figure}[h]
			\centering
			\begin{subfigure}[b]{.9\textwidth}
				\centering
				\input{figs/thompson_cat}
				\caption{\( r = e \cdot e^\prime \)}
				\label{fig:thompson_cat}
			\end{subfigure}\\
			\begin{subfigure}[b]{.9\textwidth}
				\centering
				\input{figs/thompson_plus}
				\caption{\( r = e + e^\prime \)}
				\label{fig:thompson_plus}
			\end{subfigure}\\
			\begin{subfigure}[b]{.9\textwidth}
				\centering
				\input{figs/thompson_star}
				\caption{\( r = e^\ast \)}
				\label{fig:thompson_star}
			\end{subfigure}
			\caption{Rekursive Fälle der Thompson-Konstruktion}
			\label{fig:thompson_recursive}
		\end{figure}
		%TODO Korrektheit
	\end{proof}
\end{lemma}
Ein Nebenprodukt der Thompson-Konstruktion aus dem Beweis ist folgendes Korollar.
\begin{corollary}
	Seien \( L, K \subseteq \Sigma^\ast \) FA-erkennbare Sprachen. Dann sind auch \( L \cdot K \) und \( L^\ast \) FA-erkennbar.
\end{corollary}

\subsection{Algorithmen für Reguläre Sprachen}\label{sec:regular_algorithms}
\subsection{Weitere Abschlusseigenschaften}\label{sec:regular_closure2}
\subsection{Nicht-reguläre Sprachen}\label{sec:regular_nonregular}
\subsection{Myhill-Nerode-Äquivalenz}\label{sec:regular_myhill-nerode}
\subsection{Minimierung von DFAs}\label{sec:regular_minimization}
\subsection{Anwendung: First-Longest-Match-Analyse}\label{sec:regular_first-longest-match}




\newpage
\section{Kellerautomaten und Kontextfreie Sprachen}\label{sec:contextfree}

\newpage
\section{Kontextsensitive Sprachen}\label{sec:contextsensitive}

\newpage
\section{Prozesskalküle und Petri-Netze}\label{sec:process}

\newpage
\bibliography{sources}\addcontentsline{toc}{section}{References}
\bibliographystyle{alpha}

% eof
\end{document}
